{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92e48866",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25791a74",
   "metadata": {},
   "source": [
    "#### 1.1 Import Data and Required Packages\n",
    "##### Importing Pandas, Numpy, Matplotlib, Seaborn and Warings Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b080dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "# Modelling\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45079ad",
   "metadata": {},
   "source": [
    "#### Import the CSV Data as Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e11c6255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20634923",
   "metadata": {},
   "source": [
    "#### Show Top 5 Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57eca0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all rows in output\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7e412a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>706</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>978</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>486</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>216</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>350.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>655</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>9</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
       "0         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "1         Lvl    AllPub       FR2       Gtl      Veenker      Feedr   \n",
       "2         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "3         Lvl    AllPub    Corner       Gtl      Crawfor       Norm   \n",
       "4         Lvl    AllPub       FR2       Gtl      NoRidge       Norm   \n",
       "\n",
       "  Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       Norm     1Fam     2Story            7            5       2003   \n",
       "1       Norm     1Fam     1Story            6            8       1976   \n",
       "2       Norm     1Fam     2Story            7            5       2001   \n",
       "3       Norm     1Fam     2Story            7            5       1915   \n",
       "4       Norm     1Fam     2Story            8            5       2000   \n",
       "\n",
       "   YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
       "0          2003     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "1          1976     Gable  CompShg     MetalSd     MetalSd        NaN   \n",
       "2          2002     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "3          1970     Gable  CompShg     Wd Sdng     Wd Shng        NaN   \n",
       "4          2000     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "\n",
       "   MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n",
       "0       196.0        Gd        TA      PConc       Gd       TA           No   \n",
       "1         0.0        TA        TA     CBlock       Gd       TA           Gd   \n",
       "2       162.0        Gd        TA      PConc       Gd       TA           Mn   \n",
       "3         0.0        TA        TA     BrkTil       TA       Gd           No   \n",
       "4       350.0        Gd        TA      PConc       Gd       TA           Av   \n",
       "\n",
       "  BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "0          GLQ         706          Unf           0        150          856   \n",
       "1          ALQ         978          Unf           0        284         1262   \n",
       "2          GLQ         486          Unf           0        434          920   \n",
       "3          ALQ         216          Unf           0        540          756   \n",
       "4          GLQ         655          Unf           0        490         1145   \n",
       "\n",
       "  Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
       "0    GasA        Ex          Y      SBrkr       856       854             0   \n",
       "1    GasA        Ex          Y      SBrkr      1262         0             0   \n",
       "2    GasA        Ex          Y      SBrkr       920       866             0   \n",
       "3    GasA        Gd          Y      SBrkr       961       756             0   \n",
       "4    GasA        Ex          Y      SBrkr      1145      1053             0   \n",
       "\n",
       "   GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
       "0       1710             1             0         2         1             3   \n",
       "1       1262             0             1         2         0             3   \n",
       "2       1786             1             0         2         1             3   \n",
       "3       1717             1             0         1         0             3   \n",
       "4       2198             1             0         2         1             4   \n",
       "\n",
       "   KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n",
       "0             1          Gd             8        Typ           0         NaN   \n",
       "1             1          TA             6        Typ           1          TA   \n",
       "2             1          Gd             6        Typ           1          TA   \n",
       "3             1          Gd             7        Typ           1          Gd   \n",
       "4             1          Gd             9        Typ           1          TA   \n",
       "\n",
       "  GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
       "0     Attchd       2003.0          RFn           2         548         TA   \n",
       "1     Attchd       1976.0          RFn           2         460         TA   \n",
       "2     Attchd       2001.0          RFn           2         608         TA   \n",
       "3     Detchd       1998.0          Unf           3         642         TA   \n",
       "4     Attchd       2000.0          RFn           3         836         TA   \n",
       "\n",
       "  GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "0         TA          Y           0           61              0          0   \n",
       "1         TA          Y         298            0              0          0   \n",
       "2         TA          Y           0           42              0          0   \n",
       "3         TA          Y           0           35            272          0   \n",
       "4         TA          Y         192           84              0          0   \n",
       "\n",
       "   ScreenPorch  PoolArea PoolQC Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n",
       "0            0         0    NaN   NaN         NaN        0       2    2008   \n",
       "1            0         0    NaN   NaN         NaN        0       5    2007   \n",
       "2            0         0    NaN   NaN         NaN        0       9    2008   \n",
       "3            0         0    NaN   NaN         NaN        0       2    2006   \n",
       "4            0         0    NaN   NaN         NaN        0      12    2008   \n",
       "\n",
       "  SaleType SaleCondition  SalePrice  \n",
       "0       WD        Normal     208500  \n",
       "1       WD        Normal     181500  \n",
       "2       WD        Normal     223500  \n",
       "3       WD       Abnorml     140000  \n",
       "4       WD        Normal     250000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd32281",
   "metadata": {},
   "source": [
    "#### Preparing X and Y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "56d72fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "Id= df['Id']\n",
    "X = df.drop(columns=['Id','SalePrice'],axis=1)\n",
    "y= df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cd613177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>706</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>978</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>486</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>216</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>350.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>655</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>9</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
       "0         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "1         Lvl    AllPub       FR2       Gtl      Veenker      Feedr   \n",
       "2         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "3         Lvl    AllPub    Corner       Gtl      Crawfor       Norm   \n",
       "4         Lvl    AllPub       FR2       Gtl      NoRidge       Norm   \n",
       "\n",
       "  Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       Norm     1Fam     2Story            7            5       2003   \n",
       "1       Norm     1Fam     1Story            6            8       1976   \n",
       "2       Norm     1Fam     2Story            7            5       2001   \n",
       "3       Norm     1Fam     2Story            7            5       1915   \n",
       "4       Norm     1Fam     2Story            8            5       2000   \n",
       "\n",
       "   YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
       "0          2003     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "1          1976     Gable  CompShg     MetalSd     MetalSd        NaN   \n",
       "2          2002     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "3          1970     Gable  CompShg     Wd Sdng     Wd Shng        NaN   \n",
       "4          2000     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "\n",
       "   MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n",
       "0       196.0        Gd        TA      PConc       Gd       TA           No   \n",
       "1         0.0        TA        TA     CBlock       Gd       TA           Gd   \n",
       "2       162.0        Gd        TA      PConc       Gd       TA           Mn   \n",
       "3         0.0        TA        TA     BrkTil       TA       Gd           No   \n",
       "4       350.0        Gd        TA      PConc       Gd       TA           Av   \n",
       "\n",
       "  BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "0          GLQ         706          Unf           0        150          856   \n",
       "1          ALQ         978          Unf           0        284         1262   \n",
       "2          GLQ         486          Unf           0        434          920   \n",
       "3          ALQ         216          Unf           0        540          756   \n",
       "4          GLQ         655          Unf           0        490         1145   \n",
       "\n",
       "  Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
       "0    GasA        Ex          Y      SBrkr       856       854             0   \n",
       "1    GasA        Ex          Y      SBrkr      1262         0             0   \n",
       "2    GasA        Ex          Y      SBrkr       920       866             0   \n",
       "3    GasA        Gd          Y      SBrkr       961       756             0   \n",
       "4    GasA        Ex          Y      SBrkr      1145      1053             0   \n",
       "\n",
       "   GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
       "0       1710             1             0         2         1             3   \n",
       "1       1262             0             1         2         0             3   \n",
       "2       1786             1             0         2         1             3   \n",
       "3       1717             1             0         1         0             3   \n",
       "4       2198             1             0         2         1             4   \n",
       "\n",
       "   KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n",
       "0             1          Gd             8        Typ           0         NaN   \n",
       "1             1          TA             6        Typ           1          TA   \n",
       "2             1          Gd             6        Typ           1          TA   \n",
       "3             1          Gd             7        Typ           1          Gd   \n",
       "4             1          Gd             9        Typ           1          TA   \n",
       "\n",
       "  GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
       "0     Attchd       2003.0          RFn           2         548         TA   \n",
       "1     Attchd       1976.0          RFn           2         460         TA   \n",
       "2     Attchd       2001.0          RFn           2         608         TA   \n",
       "3     Detchd       1998.0          Unf           3         642         TA   \n",
       "4     Attchd       2000.0          RFn           3         836         TA   \n",
       "\n",
       "  GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "0         TA          Y           0           61              0          0   \n",
       "1         TA          Y         298            0              0          0   \n",
       "2         TA          Y           0           42              0          0   \n",
       "3         TA          Y           0           35            272          0   \n",
       "4         TA          Y         192           84              0          0   \n",
       "\n",
       "   ScreenPorch  PoolArea PoolQC Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n",
       "0            0         0    NaN   NaN         NaN        0       2    2008   \n",
       "1            0         0    NaN   NaN         NaN        0       5    2007   \n",
       "2            0         0    NaN   NaN         NaN        0       9    2008   \n",
       "3            0         0    NaN   NaN         NaN        0       2    2006   \n",
       "4            0         0    NaN   NaN         NaN        0      12    2008   \n",
       "\n",
       "  SaleType SaleCondition  \n",
       "0       WD        Normal  \n",
       "1       WD        Normal  \n",
       "2       WD        Normal  \n",
       "3       WD       Abnorml  \n",
       "4       WD        Normal  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d9df766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['MSSubClass'] = X['MSSubClass'].astype('str') # Since MSSubClass is a categorical variable, we convert it to string type\n",
    "X['age']=X['YrSold']-X['YearBuilt'] #calculate age of the house\n",
    "X['age_mod']=X['YearRemodAdd']-X['YearBuilt'] #calculate age of the house before remodeling\n",
    "X['garage_age']=X['YrSold']-X['GarageYrBlt'] #calculate age of the garage\n",
    "X.drop(['YrSold','YearBuilt','YearRemodAdd','GarageYrBlt'],axis=1,inplace=True) #remove the columns that are not needed anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5b7b712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with 0\n",
    "X[['LotFrontage', 'MasVnrArea', 'garage_age']] = X[['LotFrontage', 'MasVnrArea', 'garage_age']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6ed26eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with high percentage of missing values & not useful for prediction\n",
    "X.drop([ 'MiscFeature', 'Alley', 'Fence'], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1e290fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "cat_features = X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "#  Numeric Transformer\n",
    "num_transformer = StandardScaler()\n",
    "\n",
    "#  Categorical Transformer\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "#  Final Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cats\", cat_transformer, cat_features),\n",
    "    (\"nums\", num_transformer, num_features),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9c68f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ab97722a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ed5c4e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1168, 303), (292, 303))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd80317",
   "metadata": {},
   "source": [
    "#### Create an Evaluate Function to give all metrics after model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8c247bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79ccb8e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression...\n",
      "Training completed for Linear Regression. and it took 0.33 seconds\n",
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 19337.7042\n",
      "- Mean Absolute Error: 12624.1577\n",
      "- R2 Score: 0.9373\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 29474.7966\n",
      "- Mean Absolute Error: 18410.0822\n",
      "- R2 Score: 0.8867\n",
      "===================================\n",
      "\n",
      "\n",
      "Training Lasso...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.527e+10, tolerance: 6.967e+08\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for Lasso. and it took 0.76 seconds\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 19343.1648\n",
      "- Mean Absolute Error: 12628.8722\n",
      "- R2 Score: 0.9373\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 28407.1718\n",
      "- Mean Absolute Error: 18037.4700\n",
      "- R2 Score: 0.8948\n",
      "===================================\n",
      "\n",
      "\n",
      "Training Ridge...\n",
      "Training completed for Ridge. and it took 0.79 seconds\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 21231.4980\n",
      "- Mean Absolute Error: 13788.2829\n",
      "- R2 Score: 0.9244\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 29689.6903\n",
      "- Mean Absolute Error: 19008.7186\n",
      "- R2 Score: 0.8851\n",
      "===================================\n",
      "\n",
      "\n",
      "Training K-Neighbors Regressor...\n",
      "Training completed for K-Neighbors Regressor. and it took 0.80 seconds\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 31233.2619\n",
      "- Mean Absolute Error: 17713.2015\n",
      "- R2 Score: 0.8364\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 38027.7691\n",
      "- Mean Absolute Error: 22374.6637\n",
      "- R2 Score: 0.8115\n",
      "===================================\n",
      "\n",
      "\n",
      "Training Decision Tree...\n",
      "Training completed for Decision Tree. and it took 1.39 seconds\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 43367.7293\n",
      "- Mean Absolute Error: 27524.1164\n",
      "- R2 Score: 0.7548\n",
      "===================================\n",
      "\n",
      "\n",
      "Training Random Forest Regressor...\n",
      "Training completed for Random Forest Regressor. and it took 11.05 seconds\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 11277.6557\n",
      "- Mean Absolute Error: 6657.3700\n",
      "- R2 Score: 0.9787\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 29281.6235\n",
      "- Mean Absolute Error: 17409.1700\n",
      "- R2 Score: 0.8882\n",
      "===================================\n",
      "\n",
      "\n",
      "Training XGBRegressor...\n",
      "Training completed for XGBRegressor. and it took 11.40 seconds\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 1350.6726\n",
      "- Mean Absolute Error: 958.2379\n",
      "- R2 Score: 0.9997\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 26056.5060\n",
      "- Mean Absolute Error: 16663.7852\n",
      "- R2 Score: 0.9115\n",
      "===================================\n",
      "\n",
      "\n",
      "Training CatBoosting Regressor...\n",
      "Training completed for CatBoosting Regressor. and it took 16.24 seconds\n",
      "CatBoosting Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 6003.9946\n",
      "- Mean Absolute Error: 4600.7414\n",
      "- R2 Score: 0.9940\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 26120.7783\n",
      "- Mean Absolute Error: 15361.1785\n",
      "- R2 Score: 0.9110\n",
      "===================================\n",
      "\n",
      "\n",
      "Training AdaBoost Regressor...\n",
      "Training completed for AdaBoost Regressor. and it took 16.78 seconds\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 27950.4962\n",
      "- Mean Absolute Error: 21815.5016\n",
      "- R2 Score: 0.8690\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 35989.4646\n",
      "- Mean Absolute Error: 25231.6474\n",
      "- R2 Score: 0.8311\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(), \n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "}\n",
    "model_list = []\n",
    "r2_list =[]\n",
    "st=time.time()\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    print(f\"Training {list(models.keys())[i]}...\")\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "    print(f\"Training completed for {list(models.keys())[i]}. and it took {time.time() - st:.2f} seconds\")\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06480b5a",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "efd4b95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>R2_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.911485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoosting Regressor</td>\n",
       "      <td>0.911047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.894794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.888217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.886737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.885080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost Regressor</td>\n",
       "      <td>0.831136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Neighbors Regressor</td>\n",
       "      <td>0.811467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.754801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name  R2_Score\n",
       "6             XGBRegressor  0.911485\n",
       "7    CatBoosting Regressor  0.911047\n",
       "1                    Lasso  0.894794\n",
       "5  Random Forest Regressor  0.888217\n",
       "0        Linear Regression  0.886737\n",
       "2                    Ridge  0.885080\n",
       "8       AdaBoost Regressor  0.831136\n",
       "3    K-Neighbors Regressor  0.811467\n",
       "4            Decision Tree  0.754801"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score']).sort_values(by=[\"R2_Score\"],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357a7c1c",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a6ad559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy of the model is 91.11\n"
     ]
    }
   ],
   "source": [
    "cat_model = CatBoostRegressor(verbose=False)\n",
    "cat_model = cat_model.fit(X_train, y_train)\n",
    "y_pred = cat_model.predict(X_test)\n",
    "score = r2_score(y_test, y_pred)*100\n",
    "print(\" Accuracy of the model is %.2f\" %score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d31453e",
   "metadata": {},
   "source": [
    "## Plot y_pred and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb557b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test,y_pred);\n",
    "plt.xlabel('Actual');\n",
    "plt.ylabel('Predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e707ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGwCAYAAABFFQqPAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAas5JREFUeJztnQd4VFX6xj8SQghCQgAJvUnvHVkVdUGislZWERFBQKRYEBZYLGAPf7CsKEV0BWw0d1WkLoLgUqRKR0RBYYEAIglFCJCc//Pe45m5M0ySmSSTae/veS4399wz956bhJk3Xy2ilFJCCCGEEBKBRAV6AYQQQgghgYJCiBBCCCERC4UQIYQQQiIWCiFCCCGERCwUQoQQQgiJWCiECCGEEBKxUAgRQgghJGIpGugFBDNZWVly+PBhKVWqlBQpUiTQyyGEEEKIF6BE4unTp6VSpUoSFZWzzYdCKAcggqpWrRroZRBCCCEkDxw8eFCqVKmS4xwKoRyAJch8I+Pj4wO9HEIIIYR4walTpyxDhvkczwkKoRww7jCIIAohQgghJLTwJqyFwdKEEEIIiVgohAghhBASsVAIEUIIISRioRAihBBCSMRCIUQIIYSQiIVCiBBCCCERC4UQIYQQQiIWCiFCCCGERCwUQoQQQgiJWCiECCGEEBKxUAgRQgghJGKhECKEEEJIYLh4ER1SJZBQCBFCCCGk8Nm/X+S660R69hRRSgIFhRAhhBBCCpd//UukRQuRdetE5s0TmTBBAgWFECGEEEIKh/PnRQYNEvnrX0XS053je/ZIoCgasDsTQgghJHLYs0fk3ntFtm1zjpUsKTJ1qkj37gFbFi1ChBBCCPEvH3wg0qqVqwhq2VLku+8CKoIAhRAhhBBC/MOZMyK9eunt7Fnn+OOPi6xZI1K7tgQausYIIYQQUvBs3SrSrZtr/E9iosi0aSJ33CHBAi1ChBBCCCk4kAo/aZJIu3auIuiaa0S2bAkqEQQohAghhBBSMKSlidxzj8jgwSIZGXqsSBGRp54SWbFCpFo1CTboGiOEEEJI/kFNoPvuE/n5Z+dYUpLIhx+K3HSTBCu0CBFCCCEk72RliYwfL3Ltta4iqFMn7QoLYhEEaBEihBBCSN44flxnhC1a5ByLjhZ58UWRkSNFooLf3kIhRAghhBDfQczP/feLHDniHKtaVWTmTB0YHSIEv1QjhBBCSPCQmSny3HMiHTu6iqDbb9eusBASQYAWIUIIIYR4x6FDIj16iKxc6RyLidExQiiSiAyxEINCiBBCCCG5s3Chjgf69Vfn2FVXicyerdtnhCh0jRFCCCEkey5cEBk+XKRLF1cRhFT5zZtDWgQBWoQIIYQQ4pn9+7XgWb/eORYXJzJhgkjfviHpCnOHQogQQgghl/PppyL9+omkpzvHGjYUmTNHpFEjCRfoGiOEEEKIk3PnRAYO1K0y7CIIomjDhrASQYAWIUIIIYRovv9ed4zftu2PAREpVUrknXdEuneXcIQWIUIIIYSIzJihA5/tIqhlSx0QHaYiCFAIEUIIIZHMmTMiDz4o0ru3yO+/O8efeEJkzRqR2rUlnKFrjBBCCIlUtmzRrrAffnCOJSaKTJ+uK0VHALQIEUIIIZGGUiKTJolcfbWrCEJ7jK1bI0YEAQohQgghJJJIS9MZYYMHi2Rk6DHUA3r6ad1IFY1TIwi6xgghhJBI4dtvdYHEX35xjiUliXz0kUinThKJ0CJECCGEhDtZWbox6nXXuYqgTp10nFCEiiBAixAhhBASzhw/rpulLlrkHIuOFnnxRZGRI0WiItsmQiFECCGEhCuI+enRQ+TwYecYYoBmztSB0YSuMUIIISTsyMwUee45kY4dXUUQssHgCqMIckCLECGEEBJOHDqkrUArVzrHihXTMUKPPRYWHeMLEgohQgghJFxYuFDHA/36q3MMlaFnz9btMshl0DVGCCGEhDoXLogMHy7SpYurCEKPsE2bKIJygBYhQgghJJTZv1/XBlq/3jkWFyfy1lsiffrQFVbQFqFDhw7JAw88IGXLlpW4uDhp0qSJbNy40XFeKSWjR4+WihUrWuc7deoke/fudbnGb7/9Jj169JD4+HgpXbq09O3bV86g6ZuNbdu2yXXXXSfFixeXqlWryrhx4y5by9y5c6V+/frWHKxjIUyCNrxZCyGEEBKyfPqpSIsWriKoUSORDRtE+valCCpoIXTy5Em55pprJCYmRhYtWiS7du2S1157TRLRoO0PIFgmTJggU6ZMkXXr1skVV1whycnJcv78eccciKCdO3fK0qVLZf78+fLNN99I//79HedPnTolnTt3lurVq8umTZtk/Pjx8txzz8nUqVMdc9asWSPdu3e3RNR3330nd955p7Xt2LHDp7UQQgghIQc+xwYN0q0y0tOd4w8/rEURxBDxDuUDI0eOVNdee22257OyslSFChXU+PHjHWNpaWkqNjZWzZw50zretWuXwm03bNjgmLNo0SJVpEgRdejQIet40qRJKjExUWVkZLjcu169eo7je++9V3Xp0sXl/u3atVOPPPKI12vJjfT0dGut2BNCCCFBwe7dSjVtirapzq1UKaU++STQKwsafPn89skiNG/ePGndurXcc889Ur58eWnRooW8++67jvP79++X1NRUywVlSEhIkHbt2snatWutY+zhDsN1DJgfFRVlWW3MnA4dOkgxpPv9ASw5e/bssaxSZo79PmaOuY83a3EnIyPDskbZN0IIISRomDFDpFUrxI84x3C8ebMOjCY+45MQ2rdvn0yePFnq1KkjS5YskYEDB8rjjz8uM/CDEbGEB0hCAzcbODbnsIeIslO0aFEpU6aMyxxP17DfI7s59vO5rcWdlJQUSyyZDbFJhBBCSMBBHO2DD4r07i3y++/O8SFDRFav1inyxP9ZY1lZWZYl55VXXrGOYRFCTA5icHqhbkGIM2rUKBk6dKjjGBYhiiFCCCEBBZWgu3UT+eEH51iZMiLTpulK0aTwLELIvmrYsKHLWIMGDeTAgQPW1xUqVLD2R48edZmDY3MO+2PHjrmcv3TpkpVJZp/j6Rr2e2Q3x34+t7W4Exsba2Wy2TdCCCEkICD6Z9IkkauvdhVBaI8BcUQRVPhCCBljiNOx88MPP1jZXaBmzZqWyFi2bJmLVQWxP+3bt7eOsU9LS7OywQzLly+3rE2I3zFzkEl28eJFxxxkmNWrV8+RoYY59vuYOeY+3qyFEEIICUrS0nRG2ODBCGDVY0iFf/pp3UiV3oqCw5co7PXr16uiRYuql19+We3du1d9/PHHqkSJEuqjjz5yzBk7dqwqXbq0+uKLL9S2bdvUHXfcoWrWrKnOnTvnmHPzzTerFi1aqHXr1qlVq1apOnXqqO7du7tkdyUlJamePXuqHTt2qFmzZln3eeeddxxzVq9eba3l1VdfVbt371ZjxoxRMTExavv27T6tJSeYNUYIIaTQWbtWqerVXbPCkpKUWro00CsLGXz5/PZJCIEvv/xSNW7c2EpDr1+/vpo6darLeaStP/vss5aQwZyOHTuqPXv2uMw5ceKEJXxKliyp4uPj1UMPPaROnz7tMmfr1q1Wqj6uUblyZUvUuDNnzhxVt25dVaxYMdWoUSO1YMECn9eSExRChBBCCo3MTKXGjVOqaFFXEXTTTUqlpgZ6dSGFL5/fRfBPARqYwgq40pA9lp6eznghQggh/uP4cZ0Vtnixcyw6WuSll0RGjBCJYmtQf31+s9cYIYQQEki+/hotF0SOHHGOIQZo5kwdGE38CiUmIYQQEgguXRIZM0akY0dXEYRsMGSFUQQVCrQIEUIIIYXNoUMi998v8s03zjF0Uxg/XuSxx9gstRChECKEEEIKkwULRFCE+MQJ5xgqQ8+eLdKyZSBXFpHQNUYIIYQUBhcuiPztbyJ/+YurCEKPMNTWowgKCLQIEUIIIf5m3z6R++4T2bDBORYXJ/LWWyJ9+tAVFkAohAghhBB/MneuSL9+yOl2jjVqpF1h2JOAQtcYIYQQ4g/OnRMZOFDk3ntdRdDDD4usX08RFCTQIkQIIYQUNN9/rzvGb9vmHCtVSmTqVO0iI0EDLUKEEEJIQTJjhkirVq4iCMebN1MEBSEUQoQQQkhBcPq0bpPRu7fI7787x4cMEVm9WqfIk6CDrjFCCCEkv6ASNFxhP/zgHCtTRmT6dJHbbgvkyoKXrCyR774T+fVXkXLlRFq0CEhPNQohQgghJK+gb/mkSSLDholkZDjHr71W5JNPdM8wcjnLl4uMHSuyZ4+ur4Sq2vXqifz97yJ//rMUJnSNEUIIIXnh5EmRrl1FHn3UKYJQD+iZZ3QjVYqg7EXQI4/oGKqSJUUqVtR7HGMc5wsRCiFCCCHEV9au1a6czz5zjiUliSxdKvLiiyJF6XDJ1h0GSxDiqSpX1kUl4Q7DHscYx3nMKyQohAghhBBvwQf0uHEiHTqI/PKLc/ymm0S2btWd5En2ICYI7rCyZS+vpo1jxFXhPOYVEhRChBBCiDccOyZy660iI0eKXLqkx6KjRVJSRBYv1hYhkjMIjEZMUGys5/PFi+vzmFdI0HZHCCGE5AbiVh54QOTIEecYYoBmzhS55ppAriy0KFdOB0YjpgruMHfOn9fnMa+QoEWIEEIIyQ5YfsaMEenUyVUE3XGHTpmnCPINxFUhO+zECZ1xZwfHv/2mz2NeIUEhRAghhHji0CEd8/PCC84PbVgrJkzQQdKIZyG+gcBopMij3Qi+vyg8ibgr7HEcH6/PF2I9IQohQgghxJ0FC0SaNRP55hvnGCpDI1vssccuD/Ql3oM6Qe+8I9K0qcjZs9rShj2Op0wp9DpCjBEihBBCDAjUfeopkddecx2//379IQ1LBsk/EDs33MDK0oQQQkjQsG+fboq6YYNzDAG9b78t8tBDtAIVNBA9aEYbYCiECCGEkLlzRfr1Ezl1yjnWuLHI7NkiDRsGcmXEzzBGiBBCSORy7pzIgAEi997rKoIeflhk3TqKoAiAFiFCCCGRye7dumP89u3OMcQAvfuuHicRAS1ChBBCIgukwk+bJtK6tasIQrwKgncpgiIKCiFCCCGRA5p69uwp0qePrl1jePJJkTVrRK66KpCrIwGArjFCCCGRASpBIxZo717nGIoiTp8uctttgVwZCSC0CBFCCAl/V9jEiSLt2rmKoGuv1eKIIiiioRAihBASvpw8KdK1q8ijj+piiQD1gJ55RuTrr3XjVBLR0DVGCCEkPEE7jO7dRX75xTmWlCTy0Ue6iSohtAgRQggJO9DEc9w4kQ4dXEXQTTeJbN1KEURcoEWIEEJI+HDsmMiDD4osWeIci44WeeklkREjAtLLigQ3FEKEEELCg+XLRXr0EElNdY5VqyYyc6bIn/4UyJWRIIbSmBBCSGhz6ZLI6NHa5WUXQXfeqQskUgSRHKBFiBBCSOjyv/+J3H+/yH//6xwrVkzk1Vd1phg7xpNcoBAihBASmixYINKrl8iJE86x2rV1x/iWLQO5MhJC0DVGCCEktEA9oGHDRP7yF1cRhPigzZspgohP0CJECCEkdNi3T+S++0Q2bHCOxcXpytG9e9MVRnyGQogQQkhoMGeOyMMPi5w65Rxr3Fi7who2DOTKSAhD1xghhJDg5tw5kUceEenWzVUE9e8vsm4dRRDJF7QIEUIICV527dICaMcO51ipUiLvvqvHCckntAgRQggJzo7x06aJtGnjKoJat9a1gSiCSCCE0HPPPSdFihRx2erXr+84f/78eRk8eLCULVtWSpYsKV27dpWjR4+6XOPAgQPSpUsXKVGihJQvX16GDx8ul1AMy8aKFSukZcuWEhsbK7Vr15bp06dftpaJEydKjRo1pHjx4tKuXTtZv369y3lv1kIIISQIOX1apGdPkT59RH7/3Tn+5JMiq1eLXHVVIFdHIt0i1KhRIzly5IhjW7VqlePck08+KV9++aXMnTtXVq5cKYcPH5a7777bcT4zM9MSQRcuXJA1a9bIjBkzLJEzGhVB/2D//v3WnBtvvFG2bNkiQ4YMkX79+skSW9+Y2bNny9ChQ2XMmDGyefNmadasmSQnJ8sx9Jjxci2EEEKCkC1bRFq1Evn4Y+dYmTIi8+aJvP66LpZISEGifGDMmDGqWbNmHs+lpaWpmJgYNXfuXMfY7t27FW6xdu1a63jhwoUqKipKpaamOuZMnjxZxcfHq4yMDOt4xIgRqlGjRi7X7tatm0pOTnYct23bVg0ePNhxnJmZqSpVqqRSUlK8Xosnzp8/r9LT0x3bwYMHrdfga0IIIX4kK0upt95SqlgxOMWc23XXKXXwYKBXR0IMfG57+/nts0Vo7969UqlSJalVq5b06NHDcnWBTZs2ycWLF6UTer38Adxm1apVk7Vr11rH2Ddp0kSSkpIcc2DJOXXqlOzcudMxx34NM8dcA9Yk3Ms+Jyoqyjo2c7xZiydSUlIkISHBsVWtWtXXbw8hhBBfOXlSpGtXkcce08USAeoBPfOMbqRapUqgV0jCGJ+EEGJx4MpavHixTJ482XJjXXfddXL69GlJTU2VYsWKSenSpV1eA9GDcwB7uwgy5825nOZALJ07d05+/fVXy8XmaY79GrmtxROjRo2S9PR0x3bw4EFfvj2EEEJ8Zc0akebNRT77zDlWoYLI0qUiL74oUpTJzcS/+PQbdssttzi+btq0qSWMqlevLnPmzJE4VPYMcRCcjY0QQoifycoSGTdOW30yM53jnTuLfPAB/nIN5OpIBJGv9HlYXOrWrSs//vijVKhQwXJbpaWlucxBphbOAezdM7fMcW5z4uPjLbFVrlw5iY6O9jjHfo3c1kIIISRA4P0bf1iPGuUUQdHRiE8QWbSIIoiEjhA6c+aM/PTTT1KxYkVp1aqVxMTEyLJlyxzn9+zZY8UQtW/f3jrGfvv27S7ZXUuXLrVETsM/KoNijv0aZo65BlxeuJd9TlZWlnVs5nizFkIIIQEA78twhf3nP86xatVEvvlG5O9/R9BnIFdHIhFforCHDRumVqxYofbv369Wr16tOnXqpMqVK6eOHTtmnR8wYICqVq2aWr58udq4caNq3769tRkuXbqkGjdurDp37qy2bNmiFi9erK688ko1atQox5x9+/apEiVKqOHDh1uZXhMnTlTR0dHWXMOsWbNUbGysmj59utq1a5fq37+/Kl26tEs2Wm5rKeioc0IIITlw8aJSzzyjVJEirllhd96p1IkTgV4dCTN8+fz2SQghjb1ixYqqWLFiqnLlytbxjz/+6Dh/7tw5NWjQIJWYmGiJmbvuuksdOXLE5Ro///yzuuWWW1RcXJwloiCuLuI/iI2vv/5aNW/e3LpPrVq11LRp0y5by1tvvWUJHcxBOv23337rct6bteQGhRAhhBQASH9HGrxdACFNHunySJsnpIDx5fO7CP4JtFUqWEGmGtLokUEG9x0hhBAfWbBApFcvkRMnnGO1a+tO8i1aBHJlJIw55cPnN52xhBBCCh7UAxo2TOQvf3EVQT16iGzeTBFEggYWaCCEEFKw7Nsnct99Ihs2OMdKlBB5+22R3r11sURCggQKIUIIIQXH7Nki/fvDN+Eca9xYu8IaNAjkygjxCF1jhBBC8s+5cyKPPKItQXYRhLH16ymCSNBCixAhhJD8sWuXSLduIjt2OMcQoPruuyL33hvIlRGSK7QIEUIIyRtIOn7/fZHWrV1FEI6/+44iiIQEFEKEEEJ85/RpkZ49Rfr21W4xw5NPiqxeLVKrViBXR4jX0DVGCCHEN2DtgSts717nWNmyItOn63T5cGgIi2f89VeRcuV0qj9bf4QtFEKEEEK8d4UhBf5vf9N1ggwdOoh8/LFIlSoS8ixfLjJ2LBpU6mcsVkykXj3dB+3Pfw706ogfoMQlhBCSOydPitx9t8jjjztFEOoBjR6tG6mGiwhCltu2bSIlS4pUrKj3OMY4zpOwg0KIEEJIzqxdqzvGf/65c6xCBZGvvhJ5/nmRokXDwx0GSxBinypXFomL0+4w7HGMcZzHPBJWUAgRQgjJWRxcd53IgQPO8eRkka1bw8tVhJgguMMQ6+Re+RrHZcro85hHwgoKIUIIIZdz9KjILbeIjBolkpmpx6KjRf7v/0QWLhQpX17CCgRGw+UXG+v5fPHi+jzmkbAiDOyZhBBCChTEwqA5amqqc6x6dZGZM0Xat5ewBNlhCIzOyNDuMHfOn9fnMY+EFbQIEUII0Vy6JPLssyKdOrmKoLvu0i6hcBVBACnyyA47cUJnx9nB8W+/6fOYR8IKCiFCCCEi//ufjvl56SWnEIAFBOny//qXSGKihDUIjEaKfKlSIocOifz+u46Rwh7HaBmC86wnFHbwJ0oIIZHOl1+KNGsm8t//Osfq1BH59luRwYMvDx72BxAdmzaJLFmi94HIzoIQfOcdkaZNRc6eFTlyRO9xPGVKeAWHEweMESKEkEgFwb+wcrzxhuv4Aw+ITJqkrSORVsQQ97vhBlaWjiAohAghJBL56SeR++4T2bjROVaihMjEiSK9ehWOFchexBB1epC6jqwtBCybIoaw0BS2GILoadWqcO9JAgYlLiGERBqzZ2srh10ENW6sj3v3LjwRxCKGJAigECKEkEgBXeJhZYElCCLDgLH160UaNCjc9bCIIQkC6BojhJBIYNcukXvvFdm50zmGTKj33hO5557gLWKIHmcsYkj8CC1ChBASziAV/v33RVq3dhVBbdpoS0ugRJB7EUNPsIghKQQohAghJFyB+6tnT5G+fbVbzDBsmMiqVSK1agVydSxiSIICCiFCCAlHYO1B5tPHHzvHEIszf77Iq69qS0ugYRFDEgTwt4sQQsIJWFLeekvk6qtF9u51jnfoILJli0iXLhJUsIghCTAMliaEkHABriS4wT7/3DX76plnREaPFikapG/5LGJIAkiQ/q8ghBDiE2vWiHTvLnLggHOsYkXtGrvxRgl6WMSQBAjKbUIICWUQU5OSol1fdhGUnKxdYaEggggJILQIEUJIqHL0qM4KW7rUORYdLfLKKyJ/+xtdS4R4AYUQIYSEIsuWifToocWQoXp1kZkzRdq3D+TKCAkp+OcCIYSEEpcu6eDnm25yFUF3362DjSmCCPEJWoQIISRU+N//dEA0iiEaUA/ojTdEBg4svGaphIQRtAgRQkgoBERD7DRs6CqC6tYVWbdOZNAgiiBC8ggtQoQQEswsWSLSv79rRhiAa+zf/xYpWTJQKyMkLKBFiBBCgpWPPhK54w5XEQTLD1pP7N8vsn59IFdHSFhAIUQIIcHIJ5+I9O7t2pk9Lk6kQQOR2rV1Q9WxY7XbjBCSZ+gaI4SQQAMxY9pLwNU1fbrIe++5zkHbiapVnbWBypQR2bPH2VyVEJInKIQIISSQLF+uLTsQNei6np4ucvGi8zyET40aIomJrq8rXlzk5EktnggheYZCiBBCAimCHnlE5NQpXRH6xAndPd6AJqkQQQkJl7/2/HmdOg9LESEkzzBGiBBCAuUOgyXIWICOHHEVQYgHKlVKxwLZxwGO0Wm+Xj3dpZ0QkmdoESKEkECA2J7t27UQunDBOQ7LUM2aIjEx2kIEq8+hQzomCO4wWIIggpA59ve/s58YIfmE/4MIIaSwgUUHwdCpqa4iCIHSKJoIVxhED0TO4MEiTZuKnD2rrUbY43jKFJE//zmQT0FIWJAvITR27FgpUqSIDBkyxDF2/vx5GTx4sJQtW1ZKliwpXbt2laP2fjiCkhgHpEuXLlKiRAkpX768DB8+XC6hf46NFStWSMuWLSU2NlZq164t05FF4cbEiROlRo0aUrx4cWnXrp2sd6up4c1aCCGkUIE15667tJCxU7GirhQNC5A9BqhTJ5HFi3XxRLwPYo9jiiBCAiuENmzYIO+88440xV8mNp588kn58ssvZe7cubJy5Uo5fPiw3I1mgH+QmZlpiaALFy7ImjVrZMaMGZbIGT16tGPO/v37rTk33nijbNmyxRJa/fr1kyWosPoHs2fPlqFDh8qYMWNk8+bN0qxZM0lOTpZjx455vRZCCCm0eKBNm5xtMr74wnkOVp86dUQqVXK2yXCPAcIcpMgnJ+s93WGEFBwqD5w+fVrVqVNHLV26VF1//fXqiSeesMbT0tJUTEyMmjt3rmPu7t27EeWn1q5dax0vXLhQRUVFqdTUVMecyZMnq/j4eJWRkWEdjxgxQjVq1Mjlnt26dVPJycmO47Zt26rBgwc7jjMzM1WlSpVUSkqK12vJjfT0dGs+9oQQkieWLVOqUyelEhIgb1y3Nm2UqlFDqaQkpRo0UKpFC73HcZ06+rWEEJ/x5fM7T39WwN0Ei00nmGxtbNq0SS5evOgyXr9+falWrZqsXbvWOsa+SZMmkpSU5JgDS86pU6dk586djjnu18Yccw1Yk3Av+5yoqCjr2MzxZi3uZGRkWOuwb4QQkq/0+L59Rb75RgdF2ylbVuSVV0T++U/GABESSlljs2bNslxRcI25k5qaKsWKFZPSpUu7jEP04JyZYxdB5rw5l9McCJNz587JyZMnLRebpznff/+912txJyUlRZ5//nmvvxeEEJKjO2z4cN0nzN4GA3E/yApLSxMZN07H+9xwg7OyNOoCGXcYISS4hNDBgwfliSeekKVLl1oByuHGqFGjrLgjA4RXVZS0J4QQX0DyBwolbt7sOo4/zKpX14USIXTsLTLYJoOQgODTnxxwNyEYGdlcRYsWtTYEIU+YMMH6GtYWuK3S8JeODWRqVahQwfoae/fMLXOc25z4+HiJi4uTcuXKSXR0tMc59mvkthZ3kKGGe9g3QgjxiYMHRW68UeT9951jCILGH1W1amkRBPDHJFLn2SKDkNARQh07dpTt27dbmVxma926tfTo0cPxdUxMjCxbtszxmj179ljp8u3bt7eOscc17NldsDBBdDRENsUfc+zXMHPMNeDyatWqlcucrKws69jMwfnc1kIIIQXKvHkizZuLrFrl6gqrX1+kfHlnVhhgiwxCQs81VqpUKWncuLHL2BVXXGHV6THjffv2tdxLZcqUscTNY489ZgmPq6++2jrfuXNnS/D07NlTxo0bZ8XrPPPMM1YANiwyYMCAAfL222/LiBEjpE+fPrJ8+XKZM2eOLFiwwHFf3KNXr16W+Grbtq384x//kLNnz8pDDz1knU9ISMh1LYQQUiBkZIiMHCny5puX1waCmwztMuyY9HgERbNFBiHh1WLjjTfesDK4ULwQWVjI9po0aZLjPFxa8+fPl4EDB1qiBEIKguaFF15wzKlZs6YlelAH6M0335QqVarIe++9Z13L0K1bNzl+/LhVfwhiqnnz5rJ48WKXAOrc1kIIIfnmxx9F7rtP1wkylCiBiq/aHTZgAFtkEBLEFEEOfaAXEawgWBqWpfT0dMYLEUIuZ9Yskf79dWNUQ5MmqPgq0qCBM4UezVURGI2YILjDUCgRIojp8YQE/PObTVcJIcRXfv9d5IkndL8wO7D+vP66qysMYofp8YQELRRChBDiCyj82q2b3hvwFydE0T33eH6NaZFBCAk6+CcJIYR4A6IIUAW6TRtXEYRjWHuyE0GEkKCGFiFCwglUMI4UF0xBP2tO10O7Hbi9Zs50fc2wYbpNhukYTwgJOSiECAkXIikot6CfNafrJSTorDBkh9n7hM2YIdKlS4E+FiGk8GHWWA4wa4yEDPggR0sHZC/hQxo1uVDb5sQJFAATeeed8BFDBf2s2V0PliFYiVCdHrWADB06iHzyiUjlyn55PEJI4X5+h6nNnJAIAh/WsGbggxwfzshYgksHexxjHOftjT9DlYJ+1uyuFxPjFENGBKEq9OjRIqhWTxFESNhAIURIqIO4Frh0YM2wt3AAOEYhP9PcM9Qp6Gf1dL0zZ0R27RJJT3fOQ8wQBNDzzzt7hRFCwgL+jyYk1IHVAnEtf7SouQxUMz55MjSbe7oHMKNHISw1sNxAqECUoIqzETG+Pqv9e4cogdRUkcOHXecgXujtt3UjVUJI2EEhREioA4GAD2sjENwpjOae/shW8xTAfMUVuj0F4oEABBDET4UKupaPr89qvndnz4ocOeJaIRqgUSpEUu3a+XsWQkjQQiFESKgD0YEMp23bdOyK3WVUGM09/ZGt5imAGc/xww8imZlaZBkrzrlzIgcOiFSrptPcfXlWzIMY2rLFNa4Iz1Czpg6URud4NkYlJGxhjBAhwQY+kNHAc8kSvc8t8BeiAKIDGVNo7on2D3gN9jj2Z3NPI1ggwkqW1N3WsccxxnHeV7ILYIYQAtHRWgBBdAG4xxDQ/Msv+nvg7bPiNc8+qy1Z9u8x0uVr1NAiiI1RCQl7+L+bkGACwuHmm0Xuvlukd2+9x3FuggKWF6SNwxpi3DzY43jKFP+kzvsrW81TADNEHVx/yObCBjEEixCuDUGDebg3Chx686wHD+r+XyiGaCqI4BqJic4O8f783hFCgga6xggJFrKrZ2OsK7nVxyns5p6+ZHD50mfLU/A3xA5EDwSQoVIlLYpwDs+I4Gm4s3Jj3jyRhx5yWphA3bq6ajREUSRU5SaEOKAQIiQYcLeuGGFhrCtwceE8hE5OH86F2dzTX9lqnoK/4f7Cs9mtNyZjzFiMcguSxvVGjhR5803X8Z49RSZN0i49QkjEwT93CAkGQrEWkF2weCKv2Wom+BuZYUb4QPBAcF28qC1AEFlGBJmAcLwmu6BmtMf4059cRRBeP326yAcfUAQREsFQCBESDHhjXcH5YKoF5EmwGLwRJ74Gf0MMmmsjlgd7bwLCZ80SadlSZPNm51iTJjoQvVevvDw5ISSMoBAiJJytK/7En9lqnoK/IXyaN9cbyC0gHOt4+GGR7t1d6wMNHCiybp1OiyeERDxsupoDbLpKCg0ICGSHZVcLCMICH/iLFwdfAK8/u957KtQIcgsI37lTpFs3vTfg//A//yny17/mb02EkLD6/KYQygEKIRKwrDG4gUwaN1xM+P0L5lTu3CpL+6PytCfwdgax8/jjutCioW1b7SLzJquMEBJRn9/MGiMkWDDuIGNdQcYVrCuwBBWEdcWf5JSt5k+LkR1UlR4wQKfB2/nb30ReflnflxBC3KBFKAdoESIBobCsJ4GsjYQAa8QW5VYbyVsQ+AxX2E8/OcdwP2SE3Xpr/q9PCAkpaBEiJJQpzFpA/hRpBVUbKSfwd9yECSLDh+vUekOHDiKffKLvQwghOUAhRAjxDl9dXP6qPG2AValPH10p2n5d9A/DhoKLhBCSCyFqbyeEFCp5aa7qz9pIq1Zpa5RdBGFNy5aJPP88RRAhxGsohAgh/mmu6m1tJFiGEOOzZIne59SkFefQKBXuNDRONaD0wJYtIjfeWEAPTQiJFPhnEyEkZyBOtm/Xlh2kpJvWFrm5uEzl6exqI6EsQJUqIk89JfLDD7m721JTdV+wr75yjsHyA2GErvOhGlBOCAkofOcghOTuEjt2TAc3IysLosVeqTk7F1dulachYlAdGiIrN3cbxA8qSttFUI0a2kWGQGmKIEJIHuG7ByGRAkSIty4ouwj65RctNEwHeFiFMGbEUE7tPzy1ysAevb4qVBDJzMzZ3QaBBYtR584iR486r9u1q7ZAtWtXwN8kQkikwTpCOcA6QiRiM77sLT8qVdLd2yGAYmK0iwvXgGipU8e79h/uafc4RqsLWIBwHXdgNUpP13OxBgPcc6+/rvuFuWeiEULIH7COECEk96KGxgXlqaihPfUd4gbWmwMHdK0eWIaio52WIcQI5dZc1b02EqxSOWWUwcoE69Hhw86xunVFZs92Nl0lhJACgK4xQsKZvGZ8ISYILiwIJuwR51Otmn4d3FnY8Jrq1fPWAy27jDJcE9lg+/frgGrDgw9qdx5FECGkgKFFiJBwBpad77/XmV7oxQVrDr6GWym7jC9YkFCLJy1NbxBOCIiGVQiuMLitII5gHYIIatPG93V5yiiDFQgCCNc3YK2TJon06lVw3xNCCLFBIURIOIMsKwQZw7qCDYLDiBr4zfE1mruajC+7G8240IwbDK4xWIVwfOaMdlVB0OQFk1GGeyHGCNdEerzdMlWrlsiCBSL16xfM94IQQjxA1xgh4QpEzcSJIpcuaREEsWEXNbAQ2TO+3N1oqPEDCxJej9dhj/R5WJDwWlhv0NDUU1Vpb4A77c039bURC2QXQbffLrJjB0UQIcTvUAgREo5AVIwYoa1B+BoiBsHJ2GCNQYwPLDDo1wUXFSw77r3BEBeEGCD3uCBYimrWdGZ0ZddiIzd27tQ1gOwB0cgimzNH5IsvPGeTEUJIAUMhREg4MnWqyNatWrzA4gNhA6sQhIzp0o44H4gaCCaIIKS/YwzzDRBDiAvCPAgoWG9gKUpIyD3gOjuwjnff1bFFu3Y5x9u21cLqnnsK+JtBCCHZwxghQsINCBIIIWO9MYHREEAmVggWIgie5GSRceO0JQgiCMHRcJehdpCpvQFXmkmbx2vtDU197SIPlxosSLNmuY7DMvTyy7pOESGEFCIUQoSEGxAkqMEDC44JkDbxQRBH2GApQqA0XFD4GsHTcIlB9CBrywRGQwxBNGEOrgMrkL3XGHAPuM4OpL9366bjjAxwr33wgcgtt/jne0EIIblA1xgh4QYECQQQRIsJlDaYoocQNnBpYS72qN0DixDcXrDKIJYI2VyYZ64BIQTBBDAXlZ+xh3jKrsUGwGsRFH311a4iCNaqBg2yL6pICCGFAIUQIeEGBAnEBVxWsALBrQUrEAQJvobIARA2EDD2KtGmmSlEFFLnIZAghEqX1oHMYO9eLWh+/lnv9+0TufJKz6n0CMa+806RIUP0dQwQVEiPRwPXvAZbE0JIAUAhREi4YYoVItbHXg0aIsiIEVh9YB0yGwQR5sClhgBpvB7i58knRT77TLe2wHUgeuA6M4HTxs2GDLQVK1zXgc7wqAQ9b55zDPdF/SEEWcPFlpdga0IIKUAohAgJN0yxQggaBCdDbMD6ghgggGDnihWdmWQGjMMKBKEDEXXFFbrxKgKgUfMHr4H4Men3eC3EDK4NgWXEDM4h8PmGG0T+9z/n9WFRgisM68ou2JoQQgoZBksTEuq4d3aHRQjCBc1U7R3nMQ8WGRMEjQBne0d5bCa9HlYadJQ37i4EOiNmCC4tCCGIJrzOBE7jGPdZulRk/HiRZcuc64N4wryrrtJfu+NtsDUhhATaIjR58mRp2rSp1dIeW/v27WXRokWO8+fPn5fBgwdL2bJlpWTJktK1a1c5ioJuNg4cOCBdunSREiVKSPny5WX48OFyyR47ILCwr5CWLVtKbGys1K5dW6ZPn37ZWiZOnCg1atSQ4sWLS7t27WT9+vUu571ZCyEhD2JrYLW5+26R3r31HscYhxhCbaB//1sE/4def10kKclZVwiixh5DZFxTECUQSqajPK41YIBuxIrihxBE+L9k/38LMQPxdN99riII8Ub//KdIYqIzNskde3VrQggJZiFUpUoVGTt2rGzatEk2btwof/7zn+WOO+6QnagQKwgneFK+/PJLmTt3rqxcuVIOHz4sd+ON+Q8yMzMtEXThwgVZs2aNzJgxwxI5o0ePdszZv3+/NefGG2+ULVu2yJAhQ6Rfv36yZMkSx5zZs2fL0KFDZcyYMbJ582Zp1qyZJCcnyzG8Uf9BbmshJOQxfcFQhBBuJ7iusLdXe4aQgWsL9YLuv1+3rEAAM9xaEDvuMUSw7MAKZDrKm3sgMNrEBbm36cC18DUEFOoQGbp21Zaqnj11zJG5rx0c//abs7o1IYQUNiqfJCYmqvfee0+lpaWpmJgYNXfuXMe53bt3411PrV271jpeuHChioqKUqmpqY45kydPVvHx8SojI8M6HjFihGrUqJHLPbp166aSk5Mdx23btlWDBw92HGdmZqpKlSqplJQU69ibtXji/PnzKj093bEdPHjQeg2+JiSoyMxU6qablEpKUqplS6VatXJuOMY4zmOenWXLlKpdW59v0ECpFi2Uql9fqTJllKpUCf8hna9xv0epUkoVLapUiRJKFS+uVHS0UrGx+mtnqUY9NnGiUllZOd8XexzXqaPPE0JIAYHPbW8/v/McLA3rzqxZs+Ts2bOWiwxWoosXL0qnTp0cc+rXry/VqlWTtWvXWsfYN2nSRJJgnv8DWHJOnTrlsCphjv0aZo65BqxJuJd9TlRUlHVs5nizFk+kpKRIQkKCY6tatWpevz2E+Bf3vmB2cgpANrFDiP9BDSBkiSE4GlajDz/ULjBTa8j9HiZYGq4suLlgRUJwNY4NyAhbt05k0CDXdXm6L/Y4NtYnQggJhWDp7du3W8IHMTiIvfnss8+kYcOGlhurWLFiUhoptzYgelKRWivIsE11EUHmvDmX0xyIpXPnzsnJkyctEeZpzvfff++4Rm5r8cSoUaMsl5sB96QYIkEJAoshRrIrRphTADJEBzK63AOsjQDK7h7I9kK9IHsmmB2cRxxSs2aez3t730AFmAdiHYSQ0BNC9erVs0RPenq6fPrpp9KrVy8rBiccQHA2NkKCHnx4I8AYFhlPXdpzC0A2sUO+3AOOL4grd2D5QawR7okK0miXkZ2o8Oa+/gZxT/ZsOjwjYpQQHE7LFCERh89/AsHSgkyuVq1aWa4kBCq/+eabUqFCBcttlWYPlhQklxy1zgHs3TO3zHFuc5ClFhcXJ+XKlZPo6GiPc+zXyG0thIRF0UR/BiC73wPWVLiz3IVNw4ZaNIVCPSBvAswJIRFFvm3BWVlZkpGRYQmjmJgYWWZLnd2zZ4+VLg9XGsAerjV7dtfSpUstkQP3mpljv4aZY64BIYZ72edgDTg2c7xZCyFhUzQR6eyI84G7B3sc29Pf83sPFFbctUunzrufRzFFuOEA9rCwBGs9IHx/YAlCmj+KTMLKhWfAnhWuCYlYfHKNIYbmlltusYKOT58+LZ988olV8wep7Qgu7tu3rxVjU6ZMGUvcPPbYY5bwuBrNFkWkc+fOluDp2bOnjBs3zorXeeaZZ6x6P8YlNWDAAHn77bdlxIgR0qdPH1m+fLnMmTNHFixY4FgH7gGXXOvWraVt27byj3/8wwrafuihh6zz3qyFkJDHvWgi3FZw8yAA2e7myU88TPnyOijaHhBtRA/cYfYq0cFeD8iXAPNAu+8IIcEphGDJefDBB+XIkSOW2EBxRYigm266yTr/xhtvWBlcKF4IKxGyvSZNmuR4PVxa8+fPl4EDB1qi5IorrrAEzQsvvOCYU7NmTUv0oA4QXG6oXfTee+9Z1zJ069ZNjh8/btUfgphq3ry5LF682CWAOre1EBIW5BaAnNd4GLjC3ntP5PHHXUUQKkTjGrAE2cWEccfZq1GHU4A5ISRsKYIc+kAvIlhB1hgEHwLDYVUiJOD4Yt0x8TBw+cAKAgGAwGfE/MCSA2uSJzGEIon9++tGq3aGDxdBSYrBg/U1YUGBeIBQggjC/5FgToVHmxAUVUVMkKcAc7gVEQOFSty0CBESMZ/fzBclJBzaaRRUPMzGjVpc2UUQBNfChSLjxsG/Hbr1gAojwJwQEnLQIpQDtAiRoMFX646v1g+8DfzjHyIjR+pWG4brrxf55BORSpXCow6P/fsYahYtQojX0CJESDiRF+uON/EwJsMLYuqOO5CF4BRBuP5zz+kGqu4iyJw3PcywDwURBFjhmhCS34KKhJACxBvLSl6ynbwtuHjwoEi/fq7VoiF8YAWCNSgcCaYK14SQgEMhREig8Dajy9tsJ9TngksM8yGO0Pdr+3ZtNXLP8DIuNbiJ7JakW28VmT5dt9IIZ4KhwjUhJCigECKksIHwmDpVBGUjYLFB2QdYe/C1qXAM902HDiKzZqETsXZZwYqD9HV3MI5rPv+8dvUYUQUxU7SoLrBoj4c5fly7g2yFTa15r7yiLSWbN9NKQgiJGBgsnQMMliZ+sQKlpIisWqUFC7q5Q6Cg9Qt+x/Df0VSGhtUmPV2PQejAqgO3FYQTgp0vXdICBq0vIKLwGvdAalwfbSQgfkzHeFwTXxtq1BD5299EvviC/bcIIWEBg6UJCeaMJVhcIGJiYrRQOXdO5MABXb8HYgfCZ+9e7e7CeYgSCB4jkuDu+uknkf37tXDB6zDPUyA1hE9iorYswcJkBJHhr3/VjVKRMcb+W4SQCIRCiJDCzvyCmwpAsGCDIIJggWUH82DJARiHAMIcI4YA3GSYj3FYfyCQYAE6c8ZzIDX6hA0YIDJnjvMcXjd5shZIb7/N/luEkIiFQoiQwsCe+QWBA7FhvNIQLBA5iN+BGILIAe7xOXYxgvif2rVFqlTR1iCcQ3yQO7gmxmHdMdSvL7J+vRZHW7Z4n5FGCCFhCIUQIYWBPfMLAc/Ywz1mMC4xWHbMsV0IQejYhRDEEqw2EFCYCzGE1yJ2yMyHuw3uM3sYIDrJI87I9NPypd4QIYSEIRRChBQG9ro+AHE4EC8QGXaRY+J3cM6OsRIZED+EOCKMQ6zg9fga4gpWIFhxEA9kgFiqXl1vO3c6Y3/c1+VOsHeUJ4SQfEIhREgg+lyhhg9ECaw6EDCI+4H4adtWn8OYseQYgWMH7jUTZI2MCGNRSksT2b3baRkCEDING2ox4x7706wZ+28RQiIaCiFCCgO4uZCKDpGDzC8IFbipEOMDIYP0eWRuLV0qMmaMM2YIAgmbXaRAMEH4mCBrZI3B3YbXwApkd6Eh+6tRI2018hT7s3Xr5evC67E3afw4z3pChJAwhe9uhAS6z1XLliIffqiDlyE4hg3TtYaQ9g6h456xhTFYg2Alwnxki+E69rR4WH4SEkTq1PEsYuyxP+y/RQiJYFhQMQdYUJH4BQgbtMJYt04ft2vnuXEphE6nTiIrV2Z/LeMSs9O4sa4PBBEDMeWpGrV793mzLvbfIoRE2Oc3W2wQUtisWOFdjzFgT1t3zyID7iIIVaJRORoiCPFCiPFBLJL9jcDE/sDiY4/9Yf8tQkgEQiFESCCqSyNY2d4Ow1RxhlusZk1tkUF2F6w2xuqDzZMFCMANBssPXGbmutjQVX7fPh0gjXHEHUEEMfaHEEIsKIQIseNP95C9urS9IzzieSBMfvlFZMgQkdKltYiBpQivQVC0CZj2JIIQaI1YoB9+cL2uSY3HdY8e1YIL14UliD3ECCHEgkKIELu1xluXVX6rS5tgZ2R6YY80eARBQ8RACCEzDFlbpuEqxJA9GNqA+Qiyfv99z9WhIbCuukrXHXr6aZH27Rn7QwghNvhuSIjdZZWXxqMm+HnJEr3Pri8XrEzI8ILoMU1Tf/xRu64ghiC87FWja9XSwgbnPIkggGDo1q1zrw4NYDXyFJRNCCERDN8RCXF3WfnSeBQC6eabRe6+W6R3b73HsSfhBOGDmj+wBplmqxA6JkUegsf0HQP42lPGl7H64PVPPaVdY6wOTQgheYJCiBC7y8qXxqO+WJEgdP71Ly2AcE37BuACQxwQrDcQP/gaLTQQLO0O5kIs9emjg6vdq1a7z2V1aEIIyRYKIULcG49CPECAIA0de4y7Nx711YpkxBZEFcQProfN3YqDMXSg37VLX8OAa8OiA7GFpqlwiS1bpsWWp6rVrA5NCCFewWBpQuyNR2GJgRCBO8lYVxC4DCsNRExerEiIy/nqK525BTeYewNVO1jD4cOXXw9tMkwMEcDaIHIgtm64wVkd2gR7Izga85khRgghOUIhRIhxLW3cqK0oJnvLND5F7A4ECrKzxo/XosLdiuQOXFwQI2vXahH0+uuX9wzzBlhx0I/MLoKyE1sQRLAK5VaxmhBCiAMKIUIgFEaMELn9di1uTEq7XbRgzo4dIv37i0yd6mpFgjvMHcTloLLzSy9pQZRd1ldOQOggsBqiyhRT9CS2IMr8nfrP9huEkDCF72SEAMTcwJoCUWNEEIQHPuxNcUOMQXhAcDRrln2AMjLDUNEZ4gHXM8HN3mIEBu4FIYRCibt36+t6ygZDNlpeU/+9wZfMOEIICTEohAgBsHQYNxRigiAwIIBgdcGxaW1xxRXa6rJ1a/YByqjkDNDjCynueJ231hPcxwRYQzwZKxAE0c8/O8WQyQarW1dno3kK2oa4g1BDij3EXWHXVyKEkBCAQogQYFxdEBye3FBmDEHTJoPMBCgjIBnZZUeOaHECEEQNAYXNiCD3a3rCWJdMnSF7bBBijHAP3Mtkg3Xtqi1G9qBtiCKMoVAjhBNin6691nfRkp/6SoQQEiJQCJHA4m1VZn+DmJcrr9RCA0HSiP3BBvcTrCnYYB2C2LAXJ4QYWrxY5N//1n3CYIWBYIEgQtVoVJEG7jFH7thFEr6GCAIQUrBMmfMQQYg9gvhCh3k0aLUHbUOcwCLlXrQRVixfLTh5ra9ECCEhBIOlSeDwd4CvL0G+K1ZoEWQXK6bJKdYGQYEKzojbgQixFyfE9VBz6L33tAAyrjQIKrjKfAXfB1zDgK8hwrAOWGPQM2zQIH1fiEd70LYRcsaShOfHWszaTbq9N646bzPj7PWVCCEkxKAQIoHBxJ7AggGLAz5s8WFuYk/gcsqvGPIktBBTA3cSLClGGAHMg4BAfy8T82MHwgFuJk/FCe0uJMQFIbAZlqTcgLiCq800VoW1x1SYBnYxZFxziM9B41Rzf5P6j+8brFH4HprAbJP6D4GE+xjLkEm3z43cMuPYuoMQEgZQCJHCxz32xLhdTOyJvVBgXlO0PQktWGu++UZbfxDkjA0iAllQxgWENWD8+HFt6YAoMX3AatQQeeWVywWacSHBQoK2GLmJIHSXf+01XWBx8mQt0uBmQqYZ1ov7GeEGMWQEDb4XjRtfbo2CMMOzmoKNGDNrxuthDcL32FcLjl1k2X9O9mBtd+sYIYSEGIwRIoWPv2NPPAX5wtqCitH2IonIAMOH/Isv6rnGBYQ1lC8v0qCBSO3a2noE8TJmjGcrlekqD7cUYnNyAteFVQmVor/4Qt8XlhysEYLFxAYZlxzWiz2OEcM0atTl4tAEbcPaBfBspoN9tWr6fnmx4LB1ByEkAuA7GCl8vIk9ce/tlV+hZWJncE+IDdNCA0IJrh98uGdnyTExQtkJCAg3U5Ha7s5y56qr9P0gmnr10tlcEEI//aQtSQBWJ+PGMm4yuLqaNxf54IPs3YUYX7VKpHVr7T7DverUcYqgvDZf9ZQZh70J1mbrDkJIiEPXGCl8/BV7YgKjkcWFD2sIIQCRYo+dMSIDlhNj/cF8uJYgRDCGeCDTc8wEH6MeDywycNnhPseO6To9EGyYg/vnlBkGMQUxgmubStPGAgRLEjLMYMGpX99pYXrgAZGHHvKuVQaeD647uMngAjPuMDwD7ptXCw7EjnlmVpYmhIQZRZTytflR5HDq1ClJSEiQ9PR0iTd/WZP8A8GAysTZxZ7A7QKLAwSNtx+29sBok2IO6w8KJOKaqL5sUslxfwgXWE3gHsPXqLljhBLGIHJMEUJYeVBIEILCfH3woL6H6UuWU8FCU6EaIguvA3C3YU0Yx2asPxCGsORAGOE5kJbvTWBzYWfjEUJImHx+0yJECh97gC9ED1xL+bFcuAdG43q4FixBqMaM2BsjNoDJpAKw+sCqAxFiXHKwpmAuhBPGIHwQJwNLDgQTRJIRVLhublWbzX1hTcFrIP7gvoJQwxpNBWnszbo9pel7Cy04hBDiNRRCJDCY2BNjucAHPywX+PD3xXKRXQZapUra1WRijUzVaJw3FhxUX7YXcDSBzka4IIi5alXnGEQb9iYWyLj33I2qxgJk0uLN65GaD2EGoYb14jpmM6/DBnGGwOj8BCLjdb5akgghJAKhECKBoyAsF9lloMGqhHgbiBeIFbi7zHmIE0/ZXab4oAEp9LgO1oPUdnttIYiX7DLE7E1WjbUI10Hl6Wef1VYvk8EGMYU5Jr4IGyxYEyfSjUUIIYUAhRAJLPm1XLhnoEFIQLBAXECMIN4GIubJJ7WF55lntPUpO9wrS5su8r42LTXZXsgAS0rSwc+w8iDFHbWMTAYbwDwcm+BtWLYgEAkhhPgdCiESPhloEB8m08tUYkacD+JxEJwNIEzQDsPbnma4lj2+yFuwJgRHwxIFYYZjZKehqjUKOtotUMbdBkEE0YRUem+rPxNCCMkXPgUgpKSkSJs2baRUqVJSvnx5ufPOO2UP3BI2zp8/L4MHD5ayZctKyZIlpWvXrnIUack2Dhw4IF26dJESJUpY1xk+fLhccvuLe8WKFdKyZUuJjY2V2rVry/Tp0y9bz8SJE6VGjRpSvHhxadeunaxfv97ntZAQx1Q/Rqo5YoLgrkL8DgQQ9jhGPI6pqAzLjK+NXXNLi3cHwslkk7nX70G2GAKvIcgwB+LNXvwQLr781FAihBDiPyG0cuVKS1h8++23snTpUrl48aJ07txZziLN9w+efPJJ+fLLL2Xu3LnW/MOHD8vdaGHwB5mZmZYIunDhgqxZs0ZmzJhhiZzRo0c75uzfv9+ac+ONN8qWLVtkyJAh0q9fP1mCDuV/MHv2bBk6dKiMGTNGNm/eLM2aNZPk5GQ5howeL9dCwgCIjhEjtOUGAsI0PDV1gkzm17hxujq0ry6uvIA1mN5h7hWYYcGCEEJaP9L3YTWyFz9k/y5CCClcVD44duwY/kxWK1eutI7T0tJUTEyMmjt3rmPO7t27rTlr1661jhcuXKiioqJUamqqY87kyZNVfHy8ysjIsI5HjBihGjVq5HKvbt26qeTkZMdx27Zt1eDBgx3HmZmZqlKlSiolJcXrteRGenq6NR97EsRs3KhU+fJKlSihVLFiShUtqvelSilVrZreEhOVatNGqehoE5Lsn83cPypKqQoVlLrpJqWWLXOuNTNTjyUlKdWypVKtWjk3HGMc5zGPEEJInvDl8ztfhUVQqAiUQTqwiGzatMmyEnXq1Mkxp379+lKtWjVZu3atdYx9kyZNJAmxEH8ASw6KH+3cudMxx34NM8dcA9Yk3Ms+Jyoqyjo2c7xZizsZGRnWOuwbCQHgRoK1Be4nWFfgfkLmFYDLDEUM4RrbsMGZqu4vcG9Ydpo1E5k3TxeFtGd/sX8XIYQEFXl+t83KyrJcVtdcc400RkdsqzZdqhQrVkxKwwVhA6IH58wcuwgy5825nOZAmJw7d05+/fVXy8XmaY79GrmtxVMMFCpRmq2qqSFDQidg2vTpQiyYyR4rzOLpSLlHnM+rr4q0aeNZ0LB/FyGEhH7WGGKFduzYIavQ6DFMGDVqlBV3ZIDwohgKQkxPMVN7CNYXWINMyw4IC3ttnsIEMT/jx+cuZlj9mRBCQlcIPfroozJ//nz55ptvpAqCPv+gQoUKltsqLS3NxRKDTC2cM3Pcs7tMJpd9jnt2F47RLyQuLk6io6OtzdMc+zVyW4s7yFDDRoKY7PpoJSfr3l2//KIzxfztArNjKkKjThEsOrAEeQOrPxNCSMDx6c9P9GeFCPrss89k+fLlUhPxEDZatWolMTExsmzZMscY0uuRLt++fXvrGPvt27e7ZHchAw0ip2HDho459muYOeYacHnhXvY5cNXh2MzxZi0kxDA9xWD5QW0g9ADDHscQIAMGiFSvXvAiyF5t2g7q/kA4Q9Dga1h0KGwIISS08CUKe+DAgSohIUGtWLFCHTlyxLH9/vvvjjkDBgxQ1apVU8uXL1cbN25U7du3tzbDpUuXVOPGjVXnzp3Vli1b1OLFi9WVV16pRo0a5Zizb98+VaJECTV8+HAr02vixIkqOjrammuYNWuWio2NVdOnT1e7du1S/fv3V6VLl3bJRsttLbnBrLECBplQyPDCzxF7bzKjzGsWLlSqXbvcs63WrNFZWwWZCRYT4znbzIxjq1zZNTuMEEJIwPDl89snIYSLetqmTZvmmHPu3Dk1aNAglZiYaImZu+66yxJLdn7++Wd1yy23qLi4OFWuXDk1bNgwdfHiRZc5X3/9tWrevLkqVqyYqlWrlss9DG+99ZYldDAH6fTffvuty3lv1pITFEIFCEQChApS2ZFWjr17anlOrylbVgsOpMjXresqhLA1aKDnzZihU9ghVIoUyb8Iwj0heJCKX6WKvr85h+vHxur7m+fIi9gjhBBSoPjy+V0E/wTaKhWsIFga2WMoEwDXHcmnSwsVnpFRBXcSMrxOnNBp5Migcg8uxmv699dp73B/IfD58GHtpoIbClWYUbgQlaLtrTMee0zktddy7ieWG3B1mfYXcL/hZ2+y0fDfBXFI6Bs2cCD8uNodhtdkF7+EdHhmghFCSFB+flMI5QCFUAEAQYE+Xyajyx5vg1891M5B2jjq7ZiMKbymbVuR7dudthlg+nGZGCD7OYBzECU7djibr+YFCBjcw3SRr1VLt8BA1We0y8Dvgnuae17EHiGEkIB/fjNXl/gXpIfDQgJx4B50jGMU48R5zDNMnSqydasWI6ZvGAQJhAl6c0EoeUqNR8r8unW6Jk9eRZC5DtaGJqkQZ2lpOdf6wVpgCYIIgtiDaMLrsMcxxnHe1x5nhBBC/A67zxP/gho5cBNlV5YAfcBMQ1QAsfDuu3oPy4yxEkGY4BjXMhhXVUGDe2NdpszC00/rXmDZ1frxRewxq4wQQoIKCiFSeFWfYSFxx73JKMQCYoE8FRZ0H/OnVxe1p7BmrM3EARWU2COEEBI00DVG/AssKAgYRqyMu3DBMWJucB7zgBELEA/uneL9Hc5mCiPCDQefMtaGYGnUvNq0KXvXll3seYId5QkhJGihECL+xdcmo0ZUwM2E+CBYWjAf8UJ2t5g/1gkBhHvi/uhHh6a7qFbdp4/I3XfroG8ERedX7BFCCAkaKISI//GlyagRFbCioM8b3E0QQLC2+MsiBPEFC5TJFDPWHYzhnL2CNTLD3MUQO8oTQkjIwvT5HGD6vJ+bpWbXZBRC48EHdSd3iBN/9Q3DvfHrj3ggCJ1KlUTuuEPkiy+0JQh99LxJ97evm3WECCEkpD6/GSxNCg9fmoxCdBiXmL+A0IFgQVYYAqIhzCDUYKWCUPM1A4wd5QkhJOSgECLBBQKkn3pKV4n2dwd5ZHJdfbXIoEFOsZLfDDB2lCeEkJCCf6qS4AGupWuvFdmwQccQ+dtrC7HjHrvDDDBCCIkoKIRIcGBaVMDtVBgVmOHmev75y2N3mAFGCCERBYUQCTymRQXS1T0VXfQGpL27x/RkByxAEDIDBng+xwwwQgiJGPhuTgoXiAoUJ1yyxFmkEMHF6C0GdxiKF/oK6v8giNkbIYS5SIcfPz57MeNLuj8hhJCQhsHSpPDILr28enWnK8oXt5hJf0dQNVLtcwNCqWVLkZSU3MUMM8AIISQioBAihRsDhE7sqBqNQGUEJG/ZIvL113nLEIM7DMIku8BmO7gfagU995z3Fh1mgBFCSNhDIUQKLwYIIqhyZacL68wZnYru3lPMW/A6uLq8nRsTI1K+fN7uRQghJCyhECL+B+4luMNgCYIIgiA6cECnoucHuMWyE1HuFaEhxlA5mtlehBBCbFAIEf9jihTC/YVmpgg+LqgUeYgciJ7sag6Zcbi5Hn6YMT6EEEJcoBAiBd8rzB307UpL06/LqxssJxB0DaFlRI+xBtmPmzUT6d+/4O9NCCEkpKEQIt6R14aiX30l8vLLWgD5QwQhYDopSeTwYef1EQtksslAhQo5p8sTQgiJWCiESN4zvrZt0+PDhonUrHm5leg//xG55x79On+1y4DoueIKXQDRFD+0C6LGjUXGjWPtH0IIIR6hECLeNUGFW6t0aacLqkQJXWX5l19EhgzR5yCQjJUILjR0dfcmtT0/wDKFYoetW4uMGCGSkCCybp0+166dTn+nJYgQQkg2UAiRnC1BEEFoggpLC+J8EG8DdxQEyMWLehxjEEIYh5XogQd0Ty5/iyDcD6Krc2dXS1SbNv69LyGEkLCBfyqTnN1hO3e6ZniZlHW4oSCEIEYA4nHQJwztK44e9b8IArBKoRgjKz4TQgjJI/z0IDkXQMyt4jPEEIA4QtNUd+HkL2CFQnFGBG/DDUcIIYTkAbrGSPYFEGFxQWxQThgL0cGDWgD5KyjaHVM7CDFLua2REEIIyQZahEj2BRAhNrztAVaYIsjcD+45xCohW40QQgjJA7QIRTLZFUjE1xAY9hYYOVVvBoUpggxwxbVty7YZhBBC8gyFUKSSU4HEG27QXyNbLDcBFEhQPwjrZaA0IYSQPMJPkEjOCEOqe8mSOtMLe1MgccUKLTAwZgg2MYRiic8+y0KJhBBC8gWFUCRnhCHrCinvsKhgj2OM4zysQtOmiSQmunZyDwaw1uuvZ+8wQggh+YZCKJIE0KZNIpMmiWzfrltluAscHJcp40xJ79RJZPZskSpVdAuLQLmgTBFHCCAIM6xn1Ci6xAghhOQbxghFWjwQLD7p6SJnzohUqqQFDkAGFtLgIS5MSjrEE4TH4MEi//63FkeFUSPIgJYdcMlBABUtqtP569fPvdErIYQQ4iUUQpHWMBWiAl+fO6f7hF15pRZGqARtRA5Ex+LFIq+95gymRho9rDKmgKK/hI8B96taVa+1Rg2RMWNEypdnFWlCCCEFCoVQJMUDmQwwiCEIIYiaQ4e0wIH4gcDAGCxDb7+trUUIpIYQ+vlnZ1d3f4D7m3Ydpn8ZxuCqO3JEiyA0UCWEEEIKEP5pHQkVou3xQNhXqKBFhymCaAQIhA7EBzKyYJGBKCpeXIslf4oge1aaqVSN+8IVhj2rRxNCCPETFEKRUCHa7nIC8fHawmLEEYSHaZqKcRxDDOG1hw9r65G/wf1xH9wTwgxiDetDUUdWjyaEEOIn6BoLZ0yFaMT/QOTYgTgy2Vhwf6E4ISwwqNYMS5GJBzp2rPDWC2sQ7o24JYg1HP/2m0jTpqweTQghxC/QIhTOQDygQjQsQ2fP6qBo7CEw4AIDEEqwAkEIIZMMFiBYZ2CZMcKkMME909J0FhtcchBErB5NCCHET9AiFI69wgz4OjlZZNUqPQcWIBOEDIsPRBA2iA+IIGSR+TsWyBsggk6e1JYgpsoTQgjxIxRC4dgrzAgHzJkyRQccQwDBRQahY8QOWmhgbP9+vYcrLNBVpCHesKFg4qOP0hJECCHEr/BTJhx7heG8PXW+Zk2dPg9RYSxBJmsMIgkWGAQq4xhusYIE1idUgvYGrA/zYaFC2jxFECGEED/DT5pw7RWGdhomdR6kpmqBARFkUuRhGUpK0qLIvamqcaPlB6yrdm2nlcesJTuwDlO4Mbe5hBBCSCCE0DfffCO33XabVKpUSYoUKSKff/65y3mllIwePVoqVqwocXFx0qlTJ9m7d6/LnN9++0169Ogh8fHxUrp0aenbt6+cQYyKjW3btsl1110nxYsXl6pVq8q4ceMuW8vcuXOlfv361pwmTZrIwoULfV5LWNQG8tQrbN06Z+o8LD5IQ4cAstcTguhAQDLO24FIMsUX8wpebzLREKCNayIoG9WicxJ5EEylS+u5hBBCSLAJobNnz0qzZs1k4sSJHs9DsEyYMEGmTJki69atkyuuuEKSk5PlPD6I/wAiaOfOnbJ06VKZP3++Ja762zqJnzp1Sjp37izVq1eXTZs2yfjx4+W5556TqVOnOuasWbNGunfvbomo7777Tu68805r27Fjh09rCZvaQAZTgBCY1HlYfiBq7MIJIggbLEh2TPB0ft1SeD1EGYQW+pU1bqxT4RHU7amBK9YGqxZcfM2aMV2eEEJI4aDyAV7+2WefOY6zsrJUhQoV1Pjx4x1jaWlpKjY2Vs2cOdM63rVrl/W6DRs2OOYsWrRIFSlSRB06dMg6njRpkkpMTFQZGRmOOSNHjlT16tVzHN97772qS5cuLutp166deuSRR7xeizvnz59X6enpju3gwYPWWvF10LBxo1LVqinVsKFSrVrprUEDperU0XtsOL9+vVI33aRUUpJS9esrFROjVPHiSsXF6a+13HHdoqM9j+dlK11arwNrWLZMb7Vr6/VgPDZW3y8qSqmiRZWqUEGfw3NgLiGEEJJH8Lnt7ed3gcYI7d+/X1JTUy0XlCEhIUHatWsna9eutY6xhzusdevWjjmYHxUVZVltzJwOHTpIMVgn/gCWnD179shJpFX/Mcd+HzPH3MebtbiTkpJizTEbXHJ+B+4gxPMsWaL32dXtMfNQ4BDB0SdO6OKHP/wg8tNPOvPrxx/11yhIiL5cyCCD9QWWGLimkBVmssPcrTGwJKEbfXaWJl+AVefFF3XHejRvRRYbtnfe0SnxAC4zuOrwM0atIOxxDlluTJcnhBASiunzEB4gCQG4NnBszmFf3i3+o2jRolKmTBmXOTWR6eR2DXMuMTHR2ud2n9zW4s6oUaNk6NChLi46v4ohb1LgPc2DKEJxxOPHXesCGRcY6gHhNRCBEB947caNl8cCGfAaiCN8XyCY8grWgO831lenzuVNUvFMN9zgrH0E1xkwLjN2lieEEFLIsI6QjdjYWGsr1BR4xOgg8Bn3hbXGpMBDwEA4eJqHGCeIBwgOiCAIIGNJgjDCuW7dRGbP1tfYvFlfJydMDBHW4C0QLRBviAHCuiBskIaP4OjseoPhNewiTwghJEgo0D+/K6BRpogcPXrUZRzH5hz2x9z6V126dMnKJLPP8XQN+z2ym2M/n9tagj4FHgLH0zwjWkxdIJOeDlECQQJxhDYVvXqJ/OlPIsOH514fCGuCtck+L7f0edynWjXtUjPp7hBhsGox2JkQQkikCSG4syAyli1b5uJeQuxP+/btrWPs09LSrGwww/LlyyUrK8uK3zFzkEl20RbLggyzevXqWW4xM8d+HzPH3MebtQR9CvysWZ7nGRcYhIhxlZkiiaaRKjhyRKfR268NvHV/4ZqIHTLp9O7nkB5vCjOyNxghhJAQxOdPK9T72bJli7WZoGR8feDAAauu0JAhQ+Sll16SefPmyfbt2+XBBx+0ag4htR00aNBAbr75Znn44Ydl/fr1snr1ann00Uflvvvus+aB+++/3wqURmo80uxnz54tb775pkv8zhNPPCGLFy+W1157Tb7//nsrvX7jxo3WtYA3awn6FHjE+niaZ+oBmRwtiA4jVEy8D8SJvQ5Q8+Z6j3nuwdLZYebhflgDRA++hhh94w0RBLzDDQbBhT2DnQkhhIQavqakff3111ZKmvvWq1cvR9r6s88+q5KSkqxU9Y4dO6o9e/a4XOPEiROqe/fuqmTJkio+Pl499NBD6vTp0y5ztm7dqq699lrrGpUrV1Zjx469bC1z5sxRdevWVcWKFVONGjVSCxYscDnvzVoKKv0u3ynw9s2kwH/4oed5LVsqVaqUTj3HjxCp6CVK6PR4M2bfkDKP9HRfU+BxPaTaI70de9wzMVGnxGdm6g3Psnix3uOYEEIICTC+fH4XwT+BFmPBClxpSKNPT0+3qmAXGLDW3HyzDoxG7I/d7YQfB1xMsK6gUvatt3qeh9R5pMobtxgwhRTdgcUou7T8nEhI0NYf0/oC7i+M0epDCCEkTD6/GcgRCCBMTI0f0+LCU5wN3FDZzYMQQtA3avZAAOUkgkzMkMGbHmKYA1cl7ge3F/ao+EwRRAghJIygEAoU9gKDOcXZ5DRv/PicO7tDzCDQ2T1wOScjoMlAw+sghD79VGT6dNfiiIQQQkiYQNdYIFxjdmBpMQUGcyoq6D4PlaT79dOFFT25wIyYMVldqA+U248aFiiTjWYKUUIAse4PIYSQMP38ZkHFQONtgUEzD8UUhw0TmTTJ9XyfPtqFNmGCFjLunebt4JxJw3cHrS+Myw3WJwgvQgghJEyhEAolUFMIFaO3bnWOQbBMnoy6BCKrV2srkHvxRJNqbzDp9nYhhIDrWrW0EMI5xCFhLLsK0YQQQkgYQCEUKnz4ocjAgTo+yAA32pAhIh984OxDBsEDIYSvTSFEuzAylanhLjMCyRRYxLEZQ4VoxCGxQjQhhJAwhkIo2DlzRgRFImfMcB1/7DGdWo+9vQ8ZtoMHneLHbg2CSwzNbE2DVsQNoQUJRJFpsQEgglghmhBCSARAIRQIvA2QRv2ge+/V1h4D6vq8/77I7bfrWkSmD5mJA8L14NL6+Wd9bNpgQFAh9sc9aAxVrJGaD1GE/mSYD0sQRBAzxAghhIQ5FEKFDbrAo5GqcWVBtKBJqV14wIKDlHm4vezd4NFAdeZM3egUvdpMHzIAl5lxm0HMXHWVFjZPPy2CHm5PPSWyfbuzYasBAdaIM2rSRGTMGJHy5bMXZoQQQkiYQSFU2CLokUdcXVkQOrD8YBzip2VLkYcf1vV7DBAuEErPP++M5zH9yrDB+nPunNMFhvm4NgKf69QRadNGZNQofQ9Yf9DUFZYgZKDBDYZq0a+8QgsQIYSQiINCqDDdYbAEubuy4uL0MQQKxMqxY063FoCFBoHSnTu7Xg8uMFwTc93T4CGIIHIgklBvyF6Y0VijTp7U1ii6wQghhEQwFEKFBWKCjCvLU4sLiJf1613HOnYU+egjHdvjDtpdQAAZEWR3ZZmiirgmLEv9++vzEDs33OBdfBIhhBASAVAIFRbGlQWXlZ2LF7VVB73DDBAmL7ygLTXufcIMqCVkrw3kqWo0rrNzpxY+pmijtwUcCSGEkAiAQqiwMNlciAmCOwzATQbXFcSQAa0tYMW59tqcr2cqPhtrDoSQCYTGGFLlTWsNVocmhBBCPEIhVFjABYXsMARGo5lpaqpuYeEulpDZdeWVuafe793rbJBqWmbYhZCpDQQLFKtDE0IIIR6hECosIE7g6kKj1B07XK1AAGJl1qycRZA99R6WHtQGQuFECB5kgRkgiBA7hHs2bszq0IQQQkg2MEq2MEGwMvqCIa3dAGtO27Yis2fr4OjcUu9hUULdH1iVEEQNCxCEELLEIIpMew2IIYgqZKIxGJoQQgjxCD8hC5vkZJHNm7WYuf56ka++Elm7Nuf0dffUe8QYQdzAioTCicY1BisTNhw3b657kDEtnhBCCMkWusYCAbq8w7JTo4bnVHpfUu/RMqN2bV0X6MEHddVpVJJGZhgtQYQQQkiOUAgFCjQ/zW/qvQEWIrTTgGsNFidCCCGEeAVNBqGWeu8JxAfhPLPDCCGEEJ+gEAql1PsTJy4vnIhj9AvDeWaHEUIIIT5BIRRKqffoFI+eZL//rgOosccx4oRwnjFBhBBCiE/wkzNUME1T0ST17FldjBF7HE+ZwuwwQgghJA8wWDqUYNNUQgghpEChEAo12DSVEEIIKTBoSiCEEEJIxEIhRAghhJCIhUKIEEIIIRELhRAhhBBCIhYKIUIIIYRELBRChBBCCIlYKIQIIYQQErFQCBFCCCEkYqEQIoQQQkjEwsrSOaD+6PR+6tSpQC+FEEIIIV5iPrfN53hOUAjlwOnTp6191apVA70UQgghhOThczwhISHHOUWUN3IpQsnKypI9e/ZIw4YN5eDBgxIfHy+RpKYhACPtuQGfPfKePVKfG/DZI+/ZI+G5lVKWCKpUqZJE5dKYnBahHMA3r3LlytbX+GUJ11+YnIjU5wZ89sh79kh9bsBnj7xnD/fnTsjFEmRgsDQhhBBCIhYKIUIIIYRELBRCuRAbGytjxoyx9pFEpD434LNH3rNH6nMDPnvkPXukPnd2MFiaEEIIIRELLUKEEEIIiVgohAghhBASsVAIEUIIISRioRAihBBCSMRCIZQDEydOlBo1akjx4sWlXbt2sn79egkmvvnmG7ntttusyplFihSRzz//3OU84uBHjx4tFStWlLi4OOnUqZPs3bvXZc5vv/0mPXr0sIpqlS5dWvr27StnzpxxmbNt2za57rrrrO8DqpGOGzfusrXMnTtX6tevb81p0qSJLFy40Oe1eEtKSoq0adNGSpUqJeXLl5c777zTqgBu5/z58zJ48GApW7aslCxZUrp27SpHjx51mXPgwAHp0qWLlChRwrrO8OHD5dKlSy5zVqxYIS1btrSyK2rXri3Tp0/3+ffEm7V4y+TJk6Vp06aOQmjt27eXRYsWhf1zuzN27Fjrd37IkCFh/+zPPfec9az2Df/Xwv25waFDh+SBBx6wrof3Dby3bNy4Mezf4/A9dv+ZY8P3Ntx/5gEBWWPkcmbNmqWKFSum3n//fbVz50718MMPq9KlS6ujR4+qYGHhwoXq6aefVv/+97+R+ac+++wzl/Njx45VCQkJ6vPPP1dbt25Vt99+u6pZs6Y6d+6cY87NN9+smjVrpr799lv13//+V9WuXVt1797dcT49PV0lJSWpHj16qB07dqiZM2equLg49c477zjmrF69WkVHR6tx48apXbt2qWeeeUbFxMSo7du3+7QWb0lOTlbTpk2z1rNlyxZ16623qmrVqqkzZ8445gwYMEBVrVpVLVu2TG3cuFFdffXV6k9/+pPj/KVLl1Tjxo1Vp06d1HfffWd9L8uVK6dGjRrlmLNv3z5VokQJNXToUOu53nrrLes5Fy9e7NPvSW5r8YV58+apBQsWqB9++EHt2bNHPfXUU9b3Gt+LcH5uO+vXr1c1atRQTZs2VU888YTX9wvVZx8zZoxq1KiROnLkiGM7fvx42D/3b7/9pqpXr6569+6t1q1bZ61xyZIl6scffwz797hjx465/LyXLl1qvcd//fXXYf0zDxQUQtnQtm1bNXjwYMdxZmamqlSpkkpJSVHBiLsQysrKUhUqVFDjx493jKWlpanY2FjrPzrALz9et2HDBsecRYsWqSJFiqhDhw5Zx5MmTVKJiYkqIyPDMWfkyJGqXr16juN7771XdenSxWU97dq1U4888ojXa8kPeNPAc6xcudJxbbxJzZ071zFn9+7d1py1a9dax3hjiIqKUqmpqY45kydPVvHx8Y5nHTFihPUBZKdbt26WEPP298SbteQX/Hzee++9iHju06dPqzp16lgfDNdff71DCIXzs0MI4YPcE+H83Hifufbaa7M9H0nvcfg9v+qqq6z7hPPPPFDQNeaBCxcuyKZNmyzTpr3vGI7Xrl0rocD+/fslNTXV5RnQdwWmTfMM2MNU3Lp1a8cczMezrlu3zjGnQ4cOUqxYMcec5ORkyxV18uRJxxz7fcwccx9v1pIf0tPTrX2ZMmWsPX52Fy9edLkfTNrVqlVzeXaYt5OSklzWjGaEO3fu9Oq5vPk98WYteSUzM1NmzZolZ8+etVxkkfDcMMHD3O++vnB/drhY4AKvVauW5eaB2yPcn3vevHnWe9M999xjuXZatGgh7777bsS9x+F7/9FHH0mfPn0s91g4/8wDBYWQB3799VfrQ8b+SwRwjF/2UMCsM6dnwB5vMHaKFi1qCQr7HE/XsN8juzn287mtJa9kZWVZcSLXXHONNG7c2HE/vKnhDTCnNeX1ufBmcu7cOa9+T7xZi69s377d8sXDrz9gwAD57LPPpGHDhmH/3BB9mzdvtmLE3AnnZ8eHKWI3Fi9ebMWI4UMX8SzorB3Oz71v3z7reevUqSNLliyRgQMHyuOPPy4zZsyIqPc4xH6mpaVJ7969HfcK1595oGD3eRLSwEKwY8cOWbVqlUQK9erVky1btliWsE8//VR69eolK1eulHDm4MGD8sQTT8jSpUutoM1I4pZbbnF8jUB5CKPq1avLnDlzrKDccAV/5MCS88orr1jHsAjh//qUKVOs3/lI4Z///Kf1OwCLIPEPtAh5oFy5chIdHX1Z5DuOK1SoIKGAWWdOz4D9sWPHXM4jqwBZFvY5nq5hv0d2c+znc1tLXnj00Udl/vz58vXXX0uVKlVcnh1mXfwVldOa8vpcyD7BB5A3vyferMVX8BcYMjxatWplWUeaNWsmb775Zlg/N0zw+F1Fhgv+oscG8TdhwgTra/wFGq7P7g7++q5bt678+OOPYf0zR/YVLJ12GjRo4HALRsJ73C+//CJfffWV9OvXzzEWzj/zQEEhlM0HDT5kli1b5vLXCY4RixEK1KxZ0/pFtD8DTJ7wi5tnwB6/wPiQMSxfvtx6VvzVaeYgTR9+YAP+KodVIjEx0THHfh8zx9zHm7X4AmLDIYLgEsJ6cX07+NnFxMS43A/+fryB2p8dLib7myTWjDcB8+ab23N583vizVryC+6ZkZER1s/dsWNHa92whJkN1gLEy5ivw/XZ3UHq908//WQJhXD+mcPd7V4W44cffrCsYeH+HmeYNm2a5dpDXJwhnH/mASNgYdpBDtIGEfE/ffp0K/Ogf//+VtqgPQo/0CCDBqmR2PCjfP31162vf/nlF0c6J9b8xRdfqG3btqk77rjDY2ppixYtrPTUVatWWRk59tRSZAUgtbRnz55Waim+L0i5dE8tLVq0qHr11VetjAFkuXhKLc1tLd4ycOBAK011xYoVLimmv//+u0tKJ1Lqly9fbqV0tm/f3trc00s7d+5speAjZfTKK6/0mF46fPhw67kmTpzoMb00t9+T3NbiC3//+9+t7Lj9+/db30ccIwPmP//5T1g/tyfsWWPh/OzDhg2zftfxM8f/NaREIxUa2ZLh/Nwok4D3lZdfflnt3btXffzxx9YaP/roI8eccH2PMxla+F4ig82dcP2ZBwoKoRxAXQX8gFFHAWmEqEMRTKCmBASQ+9arVy/rPFItn332Wes/OX6ZO3bsaNWesXPixAnrTaFkyZJWauVDDz1kCSw7qImBNFZco3LlytZ/eHfmzJmj6tata32vkJKJWjd2vFmLt3h6ZmyoLWTAm8+gQYOstFj8Z7/rrrsssWTn559/VrfccotVMwQfLPjAuXjx4mXf4+bNm1vPVatWLZd7ePt74s1avKVPnz5WbRXcC29s+D4aERTOz+2NEArXZ0dKc8WKFa174f8fju21dML1ucGXX35pfaDjPaN+/fpq6tSpLufD9T0OoGYS3tc8XSOcf+aBoAj+CZw9ihBCCCEkcDBGiBBCCCERC4UQIYQQQiIWCiFCCCGERCwUQoQQQgiJWCiECCGEEBKxUAgRQgghJGKhECKEEEJIxEIhRAghhJCIhUKIEBLyTJ8+3WpG6m9+/vlnKVKkiNXfjBASHlAIEUICzvHjx2XgwIFSrVo1iY2NtRpYJicny+rVq/12zxo1aliiBtsVV1xhdbafO3dujq+pWrWqHDlyRBo3buy3dRFCChcKIUJIwOnatat89913MmPGDKvD+Lx58+SGG26QEydO+PW+L7zwgiVscO82bdpIt27dZM2aNR7nXrhwQaKjoy2RVrRoUb+uixBSeFAIEUICSlpamvz3v/+V//u//5Mbb7xRqlevLm3btpVRo0bJ7bffbs15/fXXpUmTJpblBlaZQYMGyZkzZ3K87hdffGFZeYoXLy61atWS559/Xi5duuQyp1SpUpawqVu3rkycOFHi4uLkyy+/dFiMXnzxRXnwwQclPj5e+vfv79E1tnPnTvnLX/5izcH1rrvuOvnpp58c59977z1p0KCBtY769evLpEmTCvg7SAjJDxRChJCAUrJkSWv7/PPPJSMjw+OcqKgomTBhgiU6YDVavny5jBgxIttrQlhBwDzxxBOya9cueeedd6w4opdffjnb18DKExMTY1l+DK+++qo0a9bMshg9++yzl73m0KFD0qFDB8udhzVt2rRJ+vTp4xBcH3/8sYwePdq67+7du+WVV16xroNnIIQECQHpeU8IITY+/fRTlZiYqIoXL67+9Kc/qVGjRqmtW7dmO3/u3LmqbNmyjuNp06aphIQEx3HHjh3VK6+84vKaDz/8UFWsWNFxXL16dfXGG29YX2dkZFjz8ZY4f/58x/k777zT5Rr79++35nz33XfWMdZZs2ZNdeHCBY/rvOqqq9Qnn3ziMvbiiy+q9u3be/V9IYT4nyL4J9BijBBCzp8/b1lyvv32W1m0aJGsX7/eciv17t1bvvrqK0lJSZHvv/9eTp06ZVlcMP/s2bNSokQJy9ozZMgQy80GrrzySst1hpgeQ2Zmpstr4PpCfBCsQBiHVQruuJEjR1rzcf7hhx+Wp59+2nENuMZq1qxpWYiaN28ut956q3UvTxYe3AfXhLsNFi0D1p6QkCBHjx7183eUEOINjPgjhAQFiKG56aabrA3uo379+smYMWOsoGnE4CCrDC6mMmXKyKpVq6Rv376WGwuixh2IIMQE3X333R7vYxg+fLgltCBYkpKSrPgfO4hJygmInOwwMUzvvvuutGvXzuWcXaARQgILhRAhJChp2LChFTeEuJusrCx57bXXHJaVOXPm5PhaBEnv2bNHateuneO8cuXK5TonJ5o2bWpZgy5evGhZluxAWFWqVEn27dsnPXr0yPM9CCH+hUKIEBJQkCJ/zz33WEHGEBbIvNq4caOMGzdO7rjjDkuoQGi89dZbctttt1m1haZMmZLjNRGgDCsS6hL99a9/tQTU1q1bZceOHfLSSy8V2NofffRRa1333Xef5VaDywuuPWS91atXz7JKPf7449b4zTffbAWD49lOnjwpQ4cOLbB1EELyDrPGCCEBBW4puI7eeOMNKwMLxQrhGkN8zttvv21lbSF9Hun1OIdMLMQL5QSKMc6fP1/+85//WPWBrr76auv6SM0vSMqWLWtli8ENdv3110urVq0sV5ixDsG9hzinadOmWen/mIN4JsQZEUKCAwZLE0IIISRioUWIEEIIIRELhRAhhBBCIhYKIUIIIYRELBRChBBCCIlYKIQIIYQQErFQCBFCCCEkYqEQIoQQQkjEQiFECCGEkIiFQogQQgghEQuFECGEEEIiFgohQgghhEik8v/hLNw+ugUTBAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(x=y_test,y=y_pred,ci=None,color ='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c2fe28",
   "metadata": {},
   "source": [
    "#### Difference between Actual and Predicted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a8b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df=pd.DataFrame({'Actual Value':y_test,'Predicted Value':y_pred,'Difference':y_test-y_pred})\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0b206d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best parameters: {'learning_rate': 0.05, 'l2_leaf_reg': 1, 'iterations': 1000, 'depth': 6, 'bagging_temperature': 2}\n",
      "Best R2 score: 0.8883498867110386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define parameter grid for CatBoostRegressor\n",
    "catboost_params = {\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'iterations': [200, 500, 1000],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "    'bagging_temperature': [0, 1, 2, 3]\n",
    "}\n",
    "\n",
    "cat_model = CatBoostRegressor(verbose=False, random_state=42)\n",
    "cat_search = RandomizedSearchCV(\n",
    "    cat_model,\n",
    "    catboost_params,\n",
    "    n_iter=20,\n",
    "    scoring='r2',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "cat_search.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", cat_search.best_params_)\n",
    "print(\"Best R2 score:\", cat_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b261bb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:20:18,383] A new study created in memory with name: no-name-82c4fb60-2d4b-4ac4-8a79-fc671c887c8d\n",
      "[I 2025-06-22 16:20:19,363] Trial 0 finished with value: 0.9003406167030334 and parameters: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.03958175493965899, 'subsample': 0.8627450637856842, 'colsample_bytree': 0.9582332087869585, 'gamma': 0.2692435231879951, 'reg_alpha': 0.10199742341336249, 'reg_lambda': 2.970668305220033}. Best is trial 0 with value: 0.9003406167030334.\n",
      "[I 2025-06-22 16:20:26,002] Trial 1 finished with value: 0.9205403923988342 and parameters: {'n_estimators': 1000, 'max_depth': 10, 'learning_rate': 0.06990446482230404, 'subsample': 0.7319664059256599, 'colsample_bytree': 0.8656544676088371, 'gamma': 0.173199890410886, 'reg_alpha': 0.8465332264029652, 'reg_lambda': 2.900484538575002}. Best is trial 1 with value: 0.9205403923988342.\n",
      "[I 2025-06-22 16:20:26,963] Trial 2 finished with value: 0.8242504000663757 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.01552831429499931, 'subsample': 0.9063708060858273, 'colsample_bytree': 0.747203795734812, 'gamma': 0.08502881739874084, 'reg_alpha': 0.6815070248653055, 'reg_lambda': 1.0800448245089949}. Best is trial 1 with value: 0.9205403923988342.\n",
      "[I 2025-06-22 16:20:28,927] Trial 3 finished with value: 0.9188926815986633 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.07552601423980249, 'subsample': 0.9585790250609743, 'colsample_bytree': 0.8601908547893762, 'gamma': 0.18929552734340194, 'reg_alpha': 0.227822265434092, 'reg_lambda': 1.1267331669448315}. Best is trial 1 with value: 0.9205403923988342.\n",
      "[I 2025-06-22 16:20:29,672] Trial 4 finished with value: 0.9131098389625549 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.19238373481012838, 'subsample': 0.9240856206395236, 'colsample_bytree': 0.8464196640833185, 'gamma': 0.21200897883846553, 'reg_alpha': 0.1813460589622803, 'reg_lambda': 1.0573207044008626}. Best is trial 1 with value: 0.9205403923988342.\n",
      "[I 2025-06-22 16:20:36,073] Trial 5 finished with value: 0.920074462890625 and parameters: {'n_estimators': 1000, 'max_depth': 10, 'learning_rate': 0.012903018532223167, 'subsample': 0.6274014390297887, 'colsample_bytree': 0.8198277670633745, 'gamma': 0.048077439335499725, 'reg_alpha': 0.8756317373961783, 'reg_lambda': 2.146690178130089}. Best is trial 1 with value: 0.9205403923988342.\n",
      "[I 2025-06-22 16:20:37,170] Trial 6 finished with value: 0.9137102961540222 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.14870166503658272, 'subsample': 0.9089485807687783, 'colsample_bytree': 0.6692914490251082, 'gamma': 0.1501311214852055, 'reg_alpha': 0.6971921411041209, 'reg_lambda': 2.82267920389743}. Best is trial 1 with value: 0.9205403923988342.\n",
      "[I 2025-06-22 16:20:42,949] Trial 7 finished with value: 0.9225180149078369 and parameters: {'n_estimators': 1000, 'max_depth': 9, 'learning_rate': 0.07399887478244359, 'subsample': 0.6185071285706788, 'colsample_bytree': 0.7252952899988685, 'gamma': 0.08888552896063852, 'reg_alpha': 0.21164887272188537, 'reg_lambda': 1.2366261804246463}. Best is trial 7 with value: 0.9225180149078369.\n",
      "[I 2025-06-22 16:20:43,140] Trial 8 finished with value: 0.9140806198120117 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.07563413199869311, 'subsample': 0.8877843930829621, 'colsample_bytree': 0.9272838036945965, 'gamma': 0.28761945140432366, 'reg_alpha': 0.33292434737688537, 'reg_lambda': 1.2258339010573747}. Best is trial 7 with value: 0.9225180149078369.\n",
      "[I 2025-06-22 16:20:43,417] Trial 9 finished with value: 0.9184458255767822 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.051627760497110514, 'subsample': 0.8227010750037185, 'colsample_bytree': 0.7826156496716086, 'gamma': 0.29991584160181883, 'reg_alpha': 0.7560374497632755, 'reg_lambda': 1.7684321850764861}. Best is trial 7 with value: 0.9225180149078369.\n",
      "[I 2025-06-22 16:20:44,772] Trial 10 finished with value: 0.9182891249656677 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.026506854351511067, 'subsample': 0.6141804410469879, 'colsample_bytree': 0.6104158585564754, 'gamma': 0.008419362603261704, 'reg_alpha': 0.4862035484778231, 'reg_lambda': 1.668637569660812}. Best is trial 7 with value: 0.9225180149078369.\n",
      "[I 2025-06-22 16:20:49,383] Trial 11 finished with value: 0.9143871068954468 and parameters: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.10423864955527692, 'subsample': 0.7172775465316464, 'colsample_bytree': 0.7276042451865167, 'gamma': 0.10474106509744048, 'reg_alpha': 0.9899970461563667, 'reg_lambda': 2.425582565797316}. Best is trial 7 with value: 0.9225180149078369.\n",
      "[I 2025-06-22 16:20:56,478] Trial 12 finished with value: 0.9201048016548157 and parameters: {'n_estimators': 1000, 'max_depth': 10, 'learning_rate': 0.03642867231770059, 'subsample': 0.7198914000622523, 'colsample_bytree': 0.8878054358256143, 'gamma': 0.14087973382364416, 'reg_alpha': 0.0008433206559939066, 'reg_lambda': 2.551713783997256}. Best is trial 7 with value: 0.9225180149078369.\n",
      "[I 2025-06-22 16:21:01,695] Trial 13 finished with value: 0.9178193807601929 and parameters: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.07191968875253443, 'subsample': 0.7088258539103975, 'colsample_bytree': 0.6825878607354348, 'gamma': 0.21402395869548688, 'reg_alpha': 0.44935369176355655, 'reg_lambda': 1.4996283163526785}. Best is trial 7 with value: 0.9225180149078369.\n",
      "[I 2025-06-22 16:21:06,377] Trial 14 finished with value: 0.9188897609710693 and parameters: {'n_estimators': 1000, 'max_depth': 9, 'learning_rate': 0.12359309400251466, 'subsample': 0.6520001425880486, 'colsample_bytree': 0.7792272106545787, 'gamma': 0.09987914733050794, 'reg_alpha': 0.335178938026854, 'reg_lambda': 2.163903752035825}. Best is trial 7 with value: 0.9225180149078369.\n",
      "[I 2025-06-22 16:21:07,474] Trial 15 finished with value: 0.9189925193786621 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.025744924491157593, 'subsample': 0.775718299962319, 'colsample_bytree': 0.9115294687006378, 'gamma': 0.15431280248240192, 'reg_alpha': 0.5962623284038424, 'reg_lambda': 1.4281704003631037}. Best is trial 7 with value: 0.9225180149078369.\n",
      "[I 2025-06-22 16:21:14,585] Trial 16 finished with value: 0.9216748476028442 and parameters: {'n_estimators': 1000, 'max_depth': 9, 'learning_rate': 0.05992789070030399, 'subsample': 0.6755540908149396, 'colsample_bytree': 0.9934254371834066, 'gamma': 0.05796449017240883, 'reg_alpha': 0.8567553547232954, 'reg_lambda': 1.9479277411169718}. Best is trial 7 with value: 0.9225180149078369.\n",
      "[I 2025-06-22 16:21:19,223] Trial 17 finished with value: 0.9243180155754089 and parameters: {'n_estimators': 1000, 'max_depth': 7, 'learning_rate': 0.050847020037062096, 'subsample': 0.6810317280868757, 'colsample_bytree': 0.9858576660694509, 'gamma': 0.041368410225398534, 'reg_alpha': 0.35913575053168817, 'reg_lambda': 1.9029023793124318}. Best is trial 17 with value: 0.9243180155754089.\n",
      "[I 2025-06-22 16:21:22,927] Trial 18 finished with value: 0.9266206622123718 and parameters: {'n_estimators': 1000, 'max_depth': 7, 'learning_rate': 0.027435872666706666, 'subsample': 0.6010606567106092, 'colsample_bytree': 0.6998340598349481, 'gamma': 0.008016967612513665, 'reg_alpha': 0.3332512076320463, 'reg_lambda': 1.393920007873982}. Best is trial 18 with value: 0.9266206622123718.\n",
      "[I 2025-06-22 16:21:23,862] Trial 19 finished with value: 0.9180315136909485 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.023284479332552746, 'subsample': 0.7733345001340687, 'colsample_bytree': 0.6033904245451392, 'gamma': 0.0009929156761579183, 'reg_alpha': 0.36863437918110775, 'reg_lambda': 1.8716290291537707}. Best is trial 18 with value: 0.9266206622123718.\n",
      "[I 2025-06-22 16:21:27,417] Trial 20 finished with value: 0.9235846996307373 and parameters: {'n_estimators': 1000, 'max_depth': 7, 'learning_rate': 0.01757625993596185, 'subsample': 0.6540155385653272, 'colsample_bytree': 0.6725371364375926, 'gamma': 0.03912480048137579, 'reg_alpha': 0.5718292963787486, 'reg_lambda': 1.5198527407887392}. Best is trial 18 with value: 0.9266206622123718.\n",
      "[I 2025-06-22 16:21:30,981] Trial 21 finished with value: 0.9267676472663879 and parameters: {'n_estimators': 1000, 'max_depth': 7, 'learning_rate': 0.018299353039165724, 'subsample': 0.6693224325853203, 'colsample_bytree': 0.6655661905835695, 'gamma': 0.03388543483564738, 'reg_alpha': 0.5937994697851625, 'reg_lambda': 1.5378780468596913}. Best is trial 21 with value: 0.9267676472663879.\n",
      "[I 2025-06-22 16:21:34,457] Trial 22 finished with value: 0.9236034154891968 and parameters: {'n_estimators': 1000, 'max_depth': 7, 'learning_rate': 0.010390783818080345, 'subsample': 0.6793228236715813, 'colsample_bytree': 0.6323875335086618, 'gamma': 0.031052771555580817, 'reg_alpha': 0.4226972043052877, 'reg_lambda': 1.6545914459885347}. Best is trial 21 with value: 0.9267676472663879.\n",
      "[I 2025-06-22 16:21:36,734] Trial 23 finished with value: 0.9299582839012146 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.031243176640739143, 'subsample': 0.600022296584948, 'colsample_bytree': 0.682244379869875, 'gamma': 0.06887407696429762, 'reg_alpha': 0.540925444192529, 'reg_lambda': 1.3918132040193592}. Best is trial 23 with value: 0.9299582839012146.\n",
      "[I 2025-06-22 16:21:39,141] Trial 24 finished with value: 0.9308626651763916 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.0322544346074871, 'subsample': 0.604570183420901, 'colsample_bytree': 0.6977044890802026, 'gamma': 0.07342091688340671, 'reg_alpha': 0.5552453439865561, 'reg_lambda': 1.3284265822571282}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:21:40,907] Trial 25 finished with value: 0.9284745454788208 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.020344034777682166, 'subsample': 0.6423128271331098, 'colsample_bytree': 0.644511439280875, 'gamma': 0.06581548765814511, 'reg_alpha': 0.5562463296081812, 'reg_lambda': 1.2531509596438253}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:21:42,716] Trial 26 finished with value: 0.9284804463386536 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.03483248079234758, 'subsample': 0.6319779641087737, 'colsample_bytree': 0.6476777707213297, 'gamma': 0.11776739006475584, 'reg_alpha': 0.5212203772202509, 'reg_lambda': 1.2963029616205632}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:21:43,685] Trial 27 finished with value: 0.9189379811286926 and parameters: {'n_estimators': 500, 'max_depth': 4, 'learning_rate': 0.03453956670691461, 'subsample': 0.999576906005829, 'colsample_bytree': 0.7092908371857434, 'gamma': 0.12142692147643708, 'reg_alpha': 0.6625320776232889, 'reg_lambda': 1.3665979409480238}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:21:44,478] Trial 28 finished with value: 0.9281843304634094 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.030737752467898206, 'subsample': 0.6050528201818005, 'colsample_bytree': 0.7604956609436728, 'gamma': 0.07431660624831503, 'reg_alpha': 0.4920267520299252, 'reg_lambda': 1.2810923360188824}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:21:44,810] Trial 29 finished with value: 0.9034627079963684 and parameters: {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.041418765500233, 'subsample': 0.8476188259103078, 'colsample_bytree': 0.6400524397768586, 'gamma': 0.1185140879315423, 'reg_alpha': 0.7627311026589885, 'reg_lambda': 1.6518595117718833}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:21:47,465] Trial 30 finished with value: 0.9238347411155701 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.044269495932863126, 'subsample': 0.636601099730033, 'colsample_bytree': 0.8119375664501929, 'gamma': 0.11424308270731048, 'reg_alpha': 0.42050923365979415, 'reg_lambda': 1.0387444165086999}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:21:49,201] Trial 31 finished with value: 0.9271102547645569 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.02393805870963613, 'subsample': 0.6425641613053956, 'colsample_bytree': 0.6329741266297975, 'gamma': 0.06751531768939227, 'reg_alpha': 0.5494134425143273, 'reg_lambda': 1.233126674253661}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:21:50,974] Trial 32 finished with value: 0.9307377338409424 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.020145496749889535, 'subsample': 0.6953226218534263, 'colsample_bytree': 0.6487814505383784, 'gamma': 0.07435565193302962, 'reg_alpha': 0.6200066258854314, 'reg_lambda': 1.1667315297408083}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:21:52,424] Trial 33 finished with value: 0.92629075050354 and parameters: {'n_estimators': 1000, 'max_depth': 3, 'learning_rate': 0.03126217257975352, 'subsample': 0.7495002451541259, 'colsample_bytree': 0.6973145377236291, 'gamma': 0.08682428960742374, 'reg_alpha': 0.6386637551256393, 'reg_lambda': 1.0157590348441574}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:21:55,530] Trial 34 finished with value: 0.9279503226280212 and parameters: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.014814560744425189, 'subsample': 0.6962507915829578, 'colsample_bytree': 0.7423925012037943, 'gamma': 0.12680296634576066, 'reg_alpha': 0.7285378656180742, 'reg_lambda': 1.1384731335723974}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:21:57,303] Trial 35 finished with value: 0.9292722940444946 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.03763419262613366, 'subsample': 0.7484350096071005, 'colsample_bytree': 0.6569228021973934, 'gamma': 0.17567988798403156, 'reg_alpha': 0.524788062418339, 'reg_lambda': 1.3457355873070076}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:21:58,453] Trial 36 finished with value: 0.9276697635650635 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.020478729725996996, 'subsample': 0.7430931132397314, 'colsample_bytree': 0.6174324344617499, 'gamma': 0.18087486415034176, 'reg_alpha': 0.6192884617753049, 'reg_lambda': 1.13741588887571}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:21:58,705] Trial 37 finished with value: 0.8950291872024536 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.049585244317372365, 'subsample': 0.8140154924429825, 'colsample_bytree': 0.660623338699233, 'gamma': 0.2469001479922251, 'reg_alpha': 0.2700282091531293, 'reg_lambda': 2.112984334055872}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:00,502] Trial 38 finished with value: 0.9275498986244202 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.02955825363815053, 'subsample': 0.7617283020612489, 'colsample_bytree': 0.7110077945939935, 'gamma': 0.1613371659499562, 'reg_alpha': 0.8088652767990832, 'reg_lambda': 1.4285141474028686}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:01,732] Trial 39 finished with value: 0.9189912676811218 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.013430228234516865, 'subsample': 0.7866489097420318, 'colsample_bytree': 0.6925608168263985, 'gamma': 0.200075600592421, 'reg_alpha': 0.46086924189844725, 'reg_lambda': 1.1528164106529444}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:04,684] Trial 40 finished with value: 0.9288206100463867 and parameters: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.02269781520115, 'subsample': 0.7006962550056154, 'colsample_bytree': 0.7312152540780343, 'gamma': 0.14031794206055465, 'reg_alpha': 0.7020609403753025, 'reg_lambda': 1.5899147807997467}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:07,654] Trial 41 finished with value: 0.9286160469055176 and parameters: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.022704936427177535, 'subsample': 0.7010086852978769, 'colsample_bytree': 0.7503957123574008, 'gamma': 0.22589728861048664, 'reg_alpha': 0.7031606487699933, 'reg_lambda': 1.5666693444633937}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:09,993] Trial 42 finished with value: 0.9269911050796509 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.03905364084913039, 'subsample': 0.736464559498344, 'colsample_bytree': 0.7248488122977709, 'gamma': 0.13817922655831233, 'reg_alpha': 0.6654037532682238, 'reg_lambda': 1.7742604943972398}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:12,820] Trial 43 finished with value: 0.9248074293136597 and parameters: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.019995138352679024, 'subsample': 0.6630606594389131, 'colsample_bytree': 0.6766841292162898, 'gamma': 0.16673375270913057, 'reg_alpha': 0.5192595624263818, 'reg_lambda': 1.3612028847424285}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:15,198] Trial 44 finished with value: 0.9279229044914246 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.016266595099637182, 'subsample': 0.6917766210349542, 'colsample_bytree': 0.8368103068365844, 'gamma': 0.024039120233615784, 'reg_alpha': 0.7957618547984296, 'reg_lambda': 1.7496751146958018}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:15,482] Trial 45 finished with value: 0.9013439416885376 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05842988520371684, 'subsample': 0.6230820872362939, 'colsample_bytree': 0.774592120143763, 'gamma': 0.08047468738321506, 'reg_alpha': 0.8990506055158838, 'reg_lambda': 1.328011013489903}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:17,316] Trial 46 finished with value: 0.9251043796539307 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.011714536381794864, 'subsample': 0.719476583236231, 'colsample_bytree': 0.7278077995537746, 'gamma': 0.05341743703091485, 'reg_alpha': 0.6356447953294976, 'reg_lambda': 1.59399182187451}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:19,520] Trial 47 finished with value: 0.928094744682312 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.034514082117923936, 'subsample': 0.8021769990607133, 'colsample_bytree': 0.620637933047512, 'gamma': 0.09811788233924716, 'reg_alpha': 0.7119658135985415, 'reg_lambda': 1.4617579618167489}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:20,454] Trial 48 finished with value: 0.9243565201759338 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.02787308142273455, 'subsample': 0.7253151158262241, 'colsample_bytree': 0.6568230306380952, 'gamma': 0.13843469554877202, 'reg_alpha': 0.9169699686419015, 'reg_lambda': 1.1903725552926276}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:22,287] Trial 49 finished with value: 0.9303577542304993 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.09712067896316846, 'subsample': 0.8388581451122631, 'colsample_bytree': 0.6875473240915281, 'gamma': 0.18666152513678064, 'reg_alpha': 0.5309400445783562, 'reg_lambda': 1.0737492845433585}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:23,049] Trial 50 finished with value: 0.9181694388389587 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.10283093994111082, 'subsample': 0.8488957344515299, 'colsample_bytree': 0.6846210074832043, 'gamma': 0.19248300977666927, 'reg_alpha': 0.538223761320779, 'reg_lambda': 1.0910455642263104}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:24,931] Trial 51 finished with value: 0.9193026423454285 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.18748519234491906, 'subsample': 0.8525432480097158, 'colsample_bytree': 0.704644329440309, 'gamma': 0.17725046892996246, 'reg_alpha': 0.5924875887792003, 'reg_lambda': 1.013314527133296}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:27,293] Trial 52 finished with value: 0.9250783920288086 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.08423462158449622, 'subsample': 0.8309653868688966, 'colsample_bytree': 0.6820588070404726, 'gamma': 0.20992274319296328, 'reg_alpha': 0.39428599105930556, 'reg_lambda': 1.1998105548635727}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:29,091] Trial 53 finished with value: 0.9278974533081055 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.06308778238834051, 'subsample': 0.6149044307203781, 'colsample_bytree': 0.6589762441055922, 'gamma': 0.15155750930894044, 'reg_alpha': 0.4918910079020181, 'reg_lambda': 1.3149690558517033}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:30,907] Trial 54 finished with value: 0.9215964674949646 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.046278721482509624, 'subsample': 0.9421113063384291, 'colsample_bytree': 0.7355131140606267, 'gamma': 0.22802914481055592, 'reg_alpha': 0.6642780953804309, 'reg_lambda': 1.0861659602007998}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:33,810] Trial 55 finished with value: 0.9202113151550293 and parameters: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.024780518517864586, 'subsample': 0.8825597092789093, 'colsample_bytree': 0.7145782495649167, 'gamma': 0.09895087053241526, 'reg_alpha': 0.45527262311910766, 'reg_lambda': 2.908815143840779}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:35,274] Trial 56 finished with value: 0.926176905632019 and parameters: {'n_estimators': 1000, 'max_depth': 3, 'learning_rate': 0.03807380769233582, 'subsample': 0.7573455015848563, 'colsample_bytree': 0.7623371422406512, 'gamma': 0.18715847010724107, 'reg_alpha': 0.11428438892265169, 'reg_lambda': 1.4485415507332133}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:37,747] Trial 57 finished with value: 0.9191904664039612 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.12992453238374124, 'subsample': 0.7997882606212904, 'colsample_bytree': 0.7946604373163817, 'gamma': 0.25933860262605557, 'reg_alpha': 0.5882961864454451, 'reg_lambda': 2.333645204213847}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:38,370] Trial 58 finished with value: 0.9216248989105225 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.0329315104970305, 'subsample': 0.8855747911643742, 'colsample_bytree': 0.6732331884975665, 'gamma': 0.06253383706547355, 'reg_alpha': 0.6198987137966765, 'reg_lambda': 2.701827830394512}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:40,563] Trial 59 finished with value: 0.9301081895828247 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.02860494305073526, 'subsample': 0.6572411265535836, 'colsample_bytree': 0.6214515442559851, 'gamma': 0.016727676139787317, 'reg_alpha': 0.5199291881682748, 'reg_lambda': 1.4855016205313474}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:40,916] Trial 60 finished with value: 0.8831101059913635 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.027754656319415264, 'subsample': 0.604521877983906, 'colsample_bytree': 0.6261928320014021, 'gamma': 0.021800505894312927, 'reg_alpha': 0.5075293816837554, 'reg_lambda': 1.374492467601076}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:43,067] Trial 61 finished with value: 0.9269049167633057 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.020405454523300164, 'subsample': 0.6539887687244518, 'colsample_bytree': 0.6033888235280687, 'gamma': 0.049529093555863796, 'reg_alpha': 0.5497308596128456, 'reg_lambda': 1.2923819680494943}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:44,837] Trial 62 finished with value: 0.9295169711112976 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.022556041630260395, 'subsample': 0.6641671839839451, 'colsample_bytree': 0.652560238833219, 'gamma': 0.07411876814998213, 'reg_alpha': 0.4667046703168554, 'reg_lambda': 1.4969489358619368}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:46,625] Trial 63 finished with value: 0.9273490905761719 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.042634577219851255, 'subsample': 0.6648373182584817, 'colsample_bytree': 0.6482915541595478, 'gamma': 0.07925110485527245, 'reg_alpha': 0.4242840306524926, 'reg_lambda': 1.4687860980416396}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:48,023] Trial 64 finished with value: 0.9287194013595581 and parameters: {'n_estimators': 1000, 'max_depth': 3, 'learning_rate': 0.029884028948062396, 'subsample': 0.6244465943408678, 'colsample_bytree': 0.635819798216228, 'gamma': 0.012762982978836435, 'reg_alpha': 0.2864318656412227, 'reg_lambda': 1.2130154191394367}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:49,740] Trial 65 finished with value: 0.9258551001548767 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.018016279705453848, 'subsample': 0.6855557018874956, 'colsample_bytree': 0.6146112725348138, 'gamma': 0.04603965223393924, 'reg_alpha': 0.47883161708967664, 'reg_lambda': 1.6880498690095511}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:51,530] Trial 66 finished with value: 0.9286493062973022 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.026245443841907544, 'subsample': 0.6459357536356173, 'colsample_bytree': 0.6527993082874238, 'gamma': 0.10709454894206272, 'reg_alpha': 0.3945570736969717, 'reg_lambda': 1.3987802250450618}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:52,955] Trial 67 finished with value: 0.9264315962791443 and parameters: {'n_estimators': 1000, 'max_depth': 3, 'learning_rate': 0.021930940102146704, 'subsample': 0.6293359924451702, 'colsample_bytree': 0.6889046807360162, 'gamma': 0.09198927481714866, 'reg_alpha': 0.5660452445095604, 'reg_lambda': 1.5168698744107014}. Best is trial 24 with value: 0.9308626651763916.\n",
      "[I 2025-06-22 16:22:54,752] Trial 68 finished with value: 0.9313263893127441 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.03661701536275864, 'subsample': 0.6670108042306363, 'colsample_bytree': 0.6645939610545709, 'gamma': 0.07134133436960703, 'reg_alpha': 0.5269202542648637, 'reg_lambda': 1.2654705322976407}. Best is trial 68 with value: 0.9313263893127441.\n",
      "[I 2025-06-22 16:22:57,063] Trial 69 finished with value: 0.9257636070251465 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.08616787112933488, 'subsample': 0.6691570245826548, 'colsample_bytree': 0.6681503054342564, 'gamma': 0.06946637886347282, 'reg_alpha': 0.44245342840628765, 'reg_lambda': 1.1086237046027814}. Best is trial 68 with value: 0.9313263893127441.\n",
      "[I 2025-06-22 16:22:57,982] Trial 70 finished with value: 0.927550196647644 and parameters: {'n_estimators': 500, 'max_depth': 4, 'learning_rate': 0.03188786696586919, 'subsample': 0.6125657471892657, 'colsample_bytree': 0.6404116175787459, 'gamma': 0.058997566403935414, 'reg_alpha': 0.4788212667658832, 'reg_lambda': 1.2684830314600077}. Best is trial 68 with value: 0.9313263893127441.\n",
      "[I 2025-06-22 16:22:59,733] Trial 71 finished with value: 0.933466374874115 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.03711568041279996, 'subsample': 0.652437235761056, 'colsample_bytree': 0.624826132941059, 'gamma': 0.07487508353990774, 'reg_alpha': 0.5235685669934743, 'reg_lambda': 1.172368620374929}. Best is trial 71 with value: 0.933466374874115.\n",
      "[I 2025-06-22 16:23:01,526] Trial 72 finished with value: 0.9304413795471191 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.05338962162445075, 'subsample': 0.6536187381382982, 'colsample_bytree': 0.6257531154420284, 'gamma': 0.07530651243847211, 'reg_alpha': 0.5771723058641359, 'reg_lambda': 1.0576911004527056}. Best is trial 71 with value: 0.933466374874115.\n",
      "[I 2025-06-22 16:23:03,378] Trial 73 finished with value: 0.930182158946991 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.04909325995505557, 'subsample': 0.6398970593376256, 'colsample_bytree': 0.6064934150163165, 'gamma': 0.08681524756564961, 'reg_alpha': 0.5683788821051411, 'reg_lambda': 1.1688220814737993}. Best is trial 71 with value: 0.933466374874115.\n",
      "[I 2025-06-22 16:23:04,771] Trial 74 finished with value: 0.9275361895561218 and parameters: {'n_estimators': 1000, 'max_depth': 3, 'learning_rate': 0.04745753330991055, 'subsample': 0.6363282068096389, 'colsample_bytree': 0.6003229178334387, 'gamma': 0.08521538072443241, 'reg_alpha': 0.6013374357705976, 'reg_lambda': 1.0569155896551208}. Best is trial 71 with value: 0.933466374874115.\n",
      "[I 2025-06-22 16:23:06,537] Trial 75 finished with value: 0.9286934733390808 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.05433544489235772, 'subsample': 0.6779319603566383, 'colsample_bytree': 0.6261326440889801, 'gamma': 0.042986490351670556, 'reg_alpha': 0.5732909171205165, 'reg_lambda': 1.1523122396669385}. Best is trial 71 with value: 0.933466374874115.\n",
      "[I 2025-06-22 16:23:07,030] Trial 76 finished with value: 0.9211810827255249 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.0661975696906973, 'subsample': 0.6539597349753128, 'colsample_bytree': 0.611050493176608, 'gamma': 0.10845977032802918, 'reg_alpha': 0.5128935810358715, 'reg_lambda': 1.184429177134387}. Best is trial 71 with value: 0.933466374874115.\n",
      "[I 2025-06-22 16:23:08,789] Trial 77 finished with value: 0.9253751039505005 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.05425336461941739, 'subsample': 0.6447589383063319, 'colsample_bytree': 0.6281703654679538, 'gamma': 0.0559301066995118, 'reg_alpha': 0.6140839840791791, 'reg_lambda': 1.0575880800032014}. Best is trial 71 with value: 0.933466374874115.\n",
      "[I 2025-06-22 16:23:10,551] Trial 78 finished with value: 0.9313281774520874 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.04093341927614974, 'subsample': 0.618223388612191, 'colsample_bytree': 0.613559919480707, 'gamma': 0.0340361662466527, 'reg_alpha': 0.6479599561894687, 'reg_lambda': 1.00880849064311}. Best is trial 71 with value: 0.933466374874115.\n",
      "[I 2025-06-22 16:23:10,820] Trial 79 finished with value: 0.8951659202575684 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.04114073282740597, 'subsample': 0.6172822673649776, 'colsample_bytree': 0.8807856631307412, 'gamma': 0.0339462343610454, 'reg_alpha': 0.7470313815420115, 'reg_lambda': 1.1173621634973965}. Best is trial 71 with value: 0.933466374874115.\n",
      "[I 2025-06-22 16:23:12,614] Trial 80 finished with value: 0.9262830018997192 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.07921553292566692, 'subsample': 0.7100563238253557, 'colsample_bytree': 0.6404955821515796, 'gamma': 0.09206394499567534, 'reg_alpha': 0.5667481646190549, 'reg_lambda': 1.017329231325851}. Best is trial 71 with value: 0.933466374874115.\n",
      "[I 2025-06-22 16:23:14,371] Trial 81 finished with value: 0.9287296533584595 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.044497406706414756, 'subsample': 0.6326288261687564, 'colsample_bytree': 0.6153714591810022, 'gamma': 0.02478313583282398, 'reg_alpha': 0.6587903655320091, 'reg_lambda': 1.2267530200775991}. Best is trial 71 with value: 0.933466374874115.\n",
      "[I 2025-06-22 16:23:16,205] Trial 82 finished with value: 0.9343270063400269 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.03589579055272508, 'subsample': 0.6565557325240888, 'colsample_bytree': 0.6084965672774986, 'gamma': 0.1292947427863605, 'reg_alpha': 0.5302735916870123, 'reg_lambda': 1.159893202050106}. Best is trial 82 with value: 0.9343270063400269.\n",
      "[I 2025-06-22 16:23:17,917] Trial 83 finished with value: 0.9332968592643738 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.03518340653725671, 'subsample': 0.6848505082238875, 'colsample_bytree': 0.6008080087962068, 'gamma': 0.12996281110507887, 'reg_alpha': 0.6240674012481668, 'reg_lambda': 1.0049747668799578}. Best is trial 82 with value: 0.9343270063400269.\n",
      "[I 2025-06-22 16:23:19,698] Trial 84 finished with value: 0.9315406680107117 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.03392386057785961, 'subsample': 0.6816177580984534, 'colsample_bytree': 0.6429869000111645, 'gamma': 0.07626104614021256, 'reg_alpha': 0.6319793948834885, 'reg_lambda': 1.0005410563699308}. Best is trial 82 with value: 0.9343270063400269.\n",
      "[I 2025-06-22 16:23:21,475] Trial 85 finished with value: 0.9342299699783325 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.03630532584750695, 'subsample': 0.6798499893079362, 'colsample_bytree': 0.6359582417068748, 'gamma': 0.1270391540676039, 'reg_alpha': 0.6830268083759657, 'reg_lambda': 1.0112165443611438}. Best is trial 82 with value: 0.9343270063400269.\n",
      "[I 2025-06-22 16:23:22,881] Trial 86 finished with value: 0.9291534423828125 and parameters: {'n_estimators': 1000, 'max_depth': 3, 'learning_rate': 0.034100365195784604, 'subsample': 0.675896109842571, 'colsample_bytree': 0.6359874058014661, 'gamma': 0.12298280113378694, 'reg_alpha': 0.6801523129706915, 'reg_lambda': 1.0142552551391217}. Best is trial 82 with value: 0.9343270063400269.\n",
      "[I 2025-06-22 16:23:24,672] Trial 87 finished with value: 0.9280760288238525 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.036932293441076014, 'subsample': 0.6895764770855565, 'colsample_bytree': 0.6659794879262105, 'gamma': 0.12930983472407837, 'reg_alpha': 0.6464611471459376, 'reg_lambda': 1.115104410148087}. Best is trial 82 with value: 0.9343270063400269.\n",
      "[I 2025-06-22 16:23:26,420] Trial 88 finished with value: 0.9298608899116516 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.03945462435527552, 'subsample': 0.7022201834037674, 'colsample_bytree': 0.6122328559856032, 'gamma': 0.13233878708822125, 'reg_alpha': 0.6328131528533943, 'reg_lambda': 1.0052676700867313}. Best is trial 82 with value: 0.9343270063400269.\n",
      "[I 2025-06-22 16:23:27,583] Trial 89 finished with value: 0.9319630861282349 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.034587986827617295, 'subsample': 0.7294698612193159, 'colsample_bytree': 0.647098734031567, 'gamma': 0.11360471326131955, 'reg_alpha': 0.7328212992114689, 'reg_lambda': 1.2613090505889033}. Best is trial 82 with value: 0.9343270063400269.\n",
      "[I 2025-06-22 16:23:29,852] Trial 90 finished with value: 0.9202069640159607 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.036897570257593965, 'subsample': 0.7136647443271145, 'colsample_bytree': 0.6001987994280913, 'gamma': 0.14736292227925227, 'reg_alpha': 0.7988885185221275, 'reg_lambda': 1.2532115816750073}. Best is trial 82 with value: 0.9343270063400269.\n",
      "[I 2025-06-22 16:23:31,014] Trial 91 finished with value: 0.9245503544807434 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.03249476426691068, 'subsample': 0.6830509438579646, 'colsample_bytree': 0.6423406421968262, 'gamma': 0.10504612833638706, 'reg_alpha': 0.7407176615148481, 'reg_lambda': 1.1560909935365644}. Best is trial 82 with value: 0.9343270063400269.\n",
      "[I 2025-06-22 16:23:32,062] Trial 92 finished with value: 0.9295626878738403 and parameters: {'n_estimators': 500, 'max_depth': 4, 'learning_rate': 0.04152489809554816, 'subsample': 0.7309292509396668, 'colsample_bytree': 0.9372074190664604, 'gamma': 0.1132688474804927, 'reg_alpha': 0.7731791329137169, 'reg_lambda': 1.0963093993220911}. Best is trial 82 with value: 0.9343270063400269.\n",
      "[I 2025-06-22 16:23:33,002] Trial 93 finished with value: 0.9317219257354736 and parameters: {'n_estimators': 500, 'max_depth': 4, 'learning_rate': 0.03503001084764578, 'subsample': 0.6727433707246171, 'colsample_bytree': 0.6484185156001369, 'gamma': 0.0945863400538863, 'reg_alpha': 0.6833406149237807, 'reg_lambda': 1.2398200079169546}. Best is trial 82 with value: 0.9343270063400269.\n",
      "[I 2025-06-22 16:23:34,146] Trial 94 finished with value: 0.930640697479248 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.03540477080837345, 'subsample': 0.6692823098633048, 'colsample_bytree': 0.6316517360842732, 'gamma': 0.09529134081320188, 'reg_alpha': 0.6948743129832045, 'reg_lambda': 1.2411243819069524}. Best is trial 82 with value: 0.9343270063400269.\n",
      "[I 2025-06-22 16:23:35,090] Trial 95 finished with value: 0.9297559261322021 and parameters: {'n_estimators': 500, 'max_depth': 4, 'learning_rate': 0.03034073223495007, 'subsample': 0.6737955661229278, 'colsample_bytree': 0.6603066435196704, 'gamma': 0.16071693085045302, 'reg_alpha': 0.7798238404879418, 'reg_lambda': 1.3175423348582838}. Best is trial 82 with value: 0.9343270063400269.\n",
      "[I 2025-06-22 16:23:35,837] Trial 96 finished with value: 0.9269120097160339 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.039206039558097275, 'subsample': 0.6123083480576279, 'colsample_bytree': 0.6171742712409601, 'gamma': 0.1136543764802338, 'reg_alpha': 0.8447743476356849, 'reg_lambda': 1.000590307920076}. Best is trial 82 with value: 0.9343270063400269.\n",
      "[I 2025-06-22 16:23:36,768] Trial 97 finished with value: 0.9291573762893677 and parameters: {'n_estimators': 500, 'max_depth': 4, 'learning_rate': 0.042950593846921625, 'subsample': 0.6477276031676353, 'colsample_bytree': 0.6424848149219144, 'gamma': 0.14529238369938058, 'reg_alpha': 0.7324213389399272, 'reg_lambda': 1.2038532702593079}. Best is trial 82 with value: 0.9343270063400269.\n",
      "[I 2025-06-22 16:23:37,904] Trial 98 finished with value: 0.9325226545333862 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.033500724243647334, 'subsample': 0.7054254837157289, 'colsample_bytree': 0.6090082433824147, 'gamma': 0.1351567736125042, 'reg_alpha': 0.6801873248182615, 'reg_lambda': 1.2809635972224724}. Best is trial 82 with value: 0.9343270063400269.\n",
      "[I 2025-06-22 16:23:39,157] Trial 99 finished with value: 0.927233099937439 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.035256094006729376, 'subsample': 0.6894924219572188, 'colsample_bytree': 0.6096682485835033, 'gamma': 0.13480146276729812, 'reg_alpha': 0.7192974042327178, 'reg_lambda': 1.063304033629325}. Best is trial 82 with value: 0.9343270063400269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.03589579055272508, 'subsample': 0.6565557325240888, 'colsample_bytree': 0.6084965672774986, 'gamma': 0.1292947427863605, 'reg_alpha': 0.5302735916870123, 'reg_lambda': 1.159893202050106}\n",
      "Best R2 score: 0.9343270063400269\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [100, 300, 500, 1000]),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 0.3),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1, 3),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "    }\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return r2_score(y_test, preds)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "print(\"Best R2 score:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f2276221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGB regressor on test set:\n",
      "- MAE: 14297.08\n",
      "- RMSE: 23091.72\n",
      "- R2: 0.9305\n"
     ]
    }
   ],
   "source": [
    "bestestimator = XGBRegressor(**study.best_params)\n",
    "bestestimator.fit(X_train, y_train)\n",
    "y_pred = bestestimator.predict(X_test)\n",
    "# Evaluate the best model\n",
    "mae, rmse, r2 = evaluate_model(y_test, y_pred)\n",
    "print(f\"Best XGB regressor on test set:\\n- MAE: {mae:.2f}\\n- RMSE: {rmse:.2f}\\n- R2: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c8f990f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test.csv')\n",
    "# Preprocess the test data similarly to the training data\n",
    "test_df['MSSubClass'] = test_df['MSSubClass'].astype('str')\n",
    "test_df['age'] = test_df['YrSold'] - test_df['YearBuilt']\n",
    "test_df['age_mod'] = test_df['YearRemodAdd'] - test_df['YearBuilt']\n",
    "test_df['garage_age'] = test_df['YrSold'] - test_df['GarageYrBlt']\n",
    "test_df.drop(['YrSold', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt'], axis=1, inplace=True)\n",
    "test_df[['LotFrontage', 'MasVnrArea', 'garage_age']] = test_df[['LotFrontage', 'MasVnrArea', 'garage_age']].fillna(0)\n",
    "test_df.drop(['MiscFeature', 'Alley', 'Fence'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f379ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new =preprocessor.transform(test_df.drop(columns=['Id'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6224a2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = preprocessor.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c2a7e24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(10)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(X_test_new).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9166f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1c452c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = pd.DataFrame(X_test_new, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3df10c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nums__BsmtFullBath             2\n",
       "nums__BsmtHalfBath             2\n",
       "nums__BsmtFinSF1               1\n",
       "nums__BsmtFinSF2               1\n",
       "nums__BsmtUnfSF                1\n",
       "nums__TotalBsmtSF              1\n",
       "nums__GarageCars               1\n",
       "nums__GarageArea               1\n",
       "cats__MSSubClass_45            0\n",
       "cats__MSSubClass_50            0\n",
       "cats__MSSubClass_60            0\n",
       "cats__MSSubClass_70            0\n",
       "cats__MSSubClass_75            0\n",
       "cats__MSSubClass_80            0\n",
       "cats__MSSubClass_85            0\n",
       "cats__MSSubClass_90            0\n",
       "nums__OverallQual              0\n",
       "cats__Utilities_AllPub         0\n",
       "nums__KitchenAbvGr             0\n",
       "nums__BedroomAbvGr             0\n",
       "cats__MSZoning_C (all)         0\n",
       "cats__MSSubClass_190           0\n",
       "nums__OverallCond              0\n",
       "nums__MasVnrArea               0\n",
       "nums__1stFlrSF                 0\n",
       "nums__2ndFlrSF                 0\n",
       "nums__LowQualFinSF             0\n",
       "nums__GrLivArea                0\n",
       "nums__FullBath                 0\n",
       "nums__HalfBath                 0\n",
       "cats__MSSubClass_120           0\n",
       "cats__Utilities_NoSeWa         0\n",
       "cats__LotConfig_Corner         0\n",
       "cats__LotConfig_CulDSac        0\n",
       "cats__LotConfig_FR2            0\n",
       "cats__LotConfig_FR3            0\n",
       "cats__LotConfig_Inside         0\n",
       "cats__LandSlope_Gtl            0\n",
       "cats__LandSlope_Mod            0\n",
       "cats__LandSlope_Sev            0\n",
       "cats__Neighborhood_Blmngtn     0\n",
       "cats__Neighborhood_Blueste     0\n",
       "cats__Neighborhood_BrDale      0\n",
       "cats__Neighborhood_BrkSide     0\n",
       "cats__Neighborhood_ClearCr     0\n",
       "cats__Neighborhood_CollgCr     0\n",
       "cats__Neighborhood_Crawfor     0\n",
       "cats__Neighborhood_Edwards     0\n",
       "cats__Neighborhood_Gilbert     0\n",
       "cats__Neighborhood_IDOTRR      0\n",
       "cats__Neighborhood_MeadowV     0\n",
       "cats__Neighborhood_Mitchel     0\n",
       "cats__Neighborhood_NAmes       0\n",
       "cats__Neighborhood_NPkVill     0\n",
       "cats__Neighborhood_NWAmes      0\n",
       "cats__Neighborhood_NoRidge     0\n",
       "cats__Neighborhood_NridgHt     0\n",
       "cats__Neighborhood_OldTown     0\n",
       "cats__Neighborhood_SWISU       0\n",
       "cats__Neighborhood_Sawyer      0\n",
       "cats__Neighborhood_SawyerW     0\n",
       "cats__Neighborhood_Somerst     0\n",
       "cats__Neighborhood_StoneBr     0\n",
       "cats__Neighborhood_Timber      0\n",
       "cats__Neighborhood_Veenker     0\n",
       "cats__Condition1_Artery        0\n",
       "cats__Condition1_Feedr         0\n",
       "cats__Condition1_Norm          0\n",
       "cats__Condition1_PosA          0\n",
       "cats__Condition1_PosN          0\n",
       "cats__Condition1_RRAe          0\n",
       "cats__Condition1_RRAn          0\n",
       "cats__Condition1_RRNe          0\n",
       "cats__Condition1_RRNn          0\n",
       "cats__Condition2_Artery        0\n",
       "cats__Condition2_Feedr         0\n",
       "cats__Condition2_Norm          0\n",
       "cats__Condition2_PosA          0\n",
       "cats__Condition2_PosN          0\n",
       "cats__Condition2_RRAe          0\n",
       "cats__Condition2_RRAn          0\n",
       "cats__Condition2_RRNn          0\n",
       "cats__BldgType_1Fam            0\n",
       "cats__BldgType_2fmCon          0\n",
       "cats__BldgType_Duplex          0\n",
       "cats__BldgType_Twnhs           0\n",
       "cats__BldgType_TwnhsE          0\n",
       "cats__HouseStyle_1.5Fin        0\n",
       "cats__HouseStyle_1.5Unf        0\n",
       "cats__HouseStyle_1Story        0\n",
       "cats__HouseStyle_2.5Fin        0\n",
       "cats__HouseStyle_2.5Unf        0\n",
       "cats__HouseStyle_2Story        0\n",
       "cats__HouseStyle_SFoyer        0\n",
       "cats__HouseStyle_SLvl          0\n",
       "cats__RoofStyle_Flat           0\n",
       "cats__RoofStyle_Gable          0\n",
       "cats__RoofStyle_Gambrel        0\n",
       "cats__RoofStyle_Hip            0\n",
       "cats__RoofStyle_Mansard        0\n",
       "cats__RoofStyle_Shed           0\n",
       "cats__RoofMatl_ClyTile         0\n",
       "cats__RoofMatl_CompShg         0\n",
       "cats__RoofMatl_Membran         0\n",
       "cats__RoofMatl_Metal           0\n",
       "cats__RoofMatl_Roll            0\n",
       "cats__RoofMatl_Tar&Grv         0\n",
       "cats__RoofMatl_WdShake         0\n",
       "cats__RoofMatl_WdShngl         0\n",
       "cats__Exterior1st_AsbShng      0\n",
       "cats__Exterior1st_AsphShn      0\n",
       "cats__Exterior1st_BrkComm      0\n",
       "cats__Exterior1st_BrkFace      0\n",
       "cats__Exterior1st_CBlock       0\n",
       "cats__Exterior1st_CemntBd      0\n",
       "cats__Exterior1st_HdBoard      0\n",
       "cats__Exterior1st_ImStucc      0\n",
       "cats__Exterior1st_MetalSd      0\n",
       "cats__Exterior1st_Plywood      0\n",
       "cats__Exterior1st_Stone        0\n",
       "cats__Exterior1st_Stucco       0\n",
       "cats__Exterior1st_VinylSd      0\n",
       "cats__Exterior1st_Wd Sdng      0\n",
       "cats__Exterior1st_WdShing      0\n",
       "cats__Exterior2nd_AsbShng      0\n",
       "cats__Exterior2nd_AsphShn      0\n",
       "cats__Exterior2nd_Brk Cmn      0\n",
       "cats__Exterior2nd_BrkFace      0\n",
       "cats__Exterior2nd_CBlock       0\n",
       "cats__Exterior2nd_CmentBd      0\n",
       "cats__Exterior2nd_HdBoard      0\n",
       "cats__Exterior2nd_ImStucc      0\n",
       "cats__Exterior2nd_MetalSd      0\n",
       "cats__Exterior2nd_Other        0\n",
       "cats__Exterior2nd_Plywood      0\n",
       "cats__Exterior2nd_Stone        0\n",
       "cats__Exterior2nd_Stucco       0\n",
       "cats__Exterior2nd_VinylSd      0\n",
       "cats__Exterior2nd_Wd Sdng      0\n",
       "cats__Exterior2nd_Wd Shng      0\n",
       "cats__MasVnrType_BrkCmn        0\n",
       "cats__MasVnrType_BrkFace       0\n",
       "cats__MasVnrType_Stone         0\n",
       "cats__MasVnrType_nan           0\n",
       "cats__ExterQual_Ex             0\n",
       "cats__ExterQual_Fa             0\n",
       "cats__ExterQual_Gd             0\n",
       "cats__ExterQual_TA             0\n",
       "cats__ExterCond_Ex             0\n",
       "cats__ExterCond_Fa             0\n",
       "cats__ExterCond_Gd             0\n",
       "cats__ExterCond_Po             0\n",
       "cats__ExterCond_TA             0\n",
       "cats__Foundation_BrkTil        0\n",
       "cats__Foundation_CBlock        0\n",
       "cats__Foundation_PConc         0\n",
       "cats__Foundation_Slab          0\n",
       "cats__Foundation_Stone         0\n",
       "cats__Foundation_Wood          0\n",
       "cats__BsmtQual_Ex              0\n",
       "cats__BsmtQual_Fa              0\n",
       "cats__BsmtQual_Gd              0\n",
       "cats__BsmtQual_TA              0\n",
       "cats__BsmtQual_nan             0\n",
       "cats__BsmtCond_Fa              0\n",
       "cats__BsmtCond_Gd              0\n",
       "cats__BsmtCond_Po              0\n",
       "cats__BsmtCond_TA              0\n",
       "cats__BsmtCond_nan             0\n",
       "cats__BsmtExposure_Av          0\n",
       "cats__BsmtExposure_Gd          0\n",
       "cats__BsmtExposure_Mn          0\n",
       "cats__BsmtExposure_No          0\n",
       "cats__BsmtExposure_nan         0\n",
       "cats__BsmtFinType1_ALQ         0\n",
       "cats__BsmtFinType1_BLQ         0\n",
       "cats__BsmtFinType1_GLQ         0\n",
       "cats__BsmtFinType1_LwQ         0\n",
       "cats__BsmtFinType1_Rec         0\n",
       "cats__BsmtFinType1_Unf         0\n",
       "cats__BsmtFinType1_nan         0\n",
       "cats__BsmtFinType2_ALQ         0\n",
       "cats__BsmtFinType2_BLQ         0\n",
       "cats__BsmtFinType2_GLQ         0\n",
       "cats__BsmtFinType2_LwQ         0\n",
       "cats__BsmtFinType2_Rec         0\n",
       "cats__BsmtFinType2_Unf         0\n",
       "cats__BsmtFinType2_nan         0\n",
       "cats__Heating_Floor            0\n",
       "cats__Heating_GasA             0\n",
       "cats__Heating_GasW             0\n",
       "cats__Heating_Grav             0\n",
       "cats__Heating_OthW             0\n",
       "cats__Heating_Wall             0\n",
       "cats__HeatingQC_Ex             0\n",
       "cats__HeatingQC_Fa             0\n",
       "cats__HeatingQC_Gd             0\n",
       "cats__HeatingQC_Po             0\n",
       "cats__HeatingQC_TA             0\n",
       "cats__CentralAir_N             0\n",
       "cats__CentralAir_Y             0\n",
       "cats__Electrical_FuseA         0\n",
       "cats__Electrical_FuseF         0\n",
       "cats__Electrical_FuseP         0\n",
       "cats__Electrical_Mix           0\n",
       "cats__Electrical_SBrkr         0\n",
       "cats__Electrical_nan           0\n",
       "cats__KitchenQual_Ex           0\n",
       "cats__KitchenQual_Fa           0\n",
       "cats__KitchenQual_Gd           0\n",
       "cats__KitchenQual_TA           0\n",
       "cats__Functional_Maj1          0\n",
       "cats__Functional_Maj2          0\n",
       "cats__Functional_Min1          0\n",
       "cats__Functional_Min2          0\n",
       "cats__Functional_Mod           0\n",
       "cats__Functional_Sev           0\n",
       "cats__Functional_Typ           0\n",
       "cats__FireplaceQu_Ex           0\n",
       "cats__FireplaceQu_Fa           0\n",
       "cats__FireplaceQu_Gd           0\n",
       "cats__FireplaceQu_Po           0\n",
       "cats__FireplaceQu_TA           0\n",
       "cats__FireplaceQu_nan          0\n",
       "cats__GarageType_2Types        0\n",
       "cats__GarageType_Attchd        0\n",
       "cats__GarageType_Basment       0\n",
       "cats__GarageType_BuiltIn       0\n",
       "cats__GarageType_CarPort       0\n",
       "cats__GarageType_Detchd        0\n",
       "cats__GarageType_nan           0\n",
       "cats__GarageFinish_Fin         0\n",
       "cats__GarageFinish_RFn         0\n",
       "cats__GarageFinish_Unf         0\n",
       "cats__GarageFinish_nan         0\n",
       "cats__GarageQual_Ex            0\n",
       "cats__GarageQual_Fa            0\n",
       "cats__GarageQual_Gd            0\n",
       "cats__GarageQual_Po            0\n",
       "cats__GarageQual_TA            0\n",
       "cats__GarageQual_nan           0\n",
       "cats__GarageCond_Ex            0\n",
       "cats__GarageCond_Fa            0\n",
       "cats__GarageCond_Gd            0\n",
       "cats__GarageCond_Po            0\n",
       "cats__GarageCond_TA            0\n",
       "cats__GarageCond_nan           0\n",
       "cats__PavedDrive_N             0\n",
       "cats__PavedDrive_P             0\n",
       "cats__PavedDrive_Y             0\n",
       "cats__PoolQC_Ex                0\n",
       "cats__PoolQC_Fa                0\n",
       "cats__PoolQC_Gd                0\n",
       "cats__PoolQC_nan               0\n",
       "cats__SaleType_COD             0\n",
       "cats__SaleType_CWD             0\n",
       "cats__SaleType_Con             0\n",
       "cats__SaleType_ConLD           0\n",
       "cats__SaleType_ConLI           0\n",
       "cats__SaleType_ConLw           0\n",
       "cats__SaleType_New             0\n",
       "cats__SaleType_Oth             0\n",
       "cats__SaleType_WD              0\n",
       "cats__SaleCondition_Abnorml    0\n",
       "cats__SaleCondition_AdjLand    0\n",
       "cats__SaleCondition_Alloca     0\n",
       "cats__SaleCondition_Family     0\n",
       "cats__SaleCondition_Normal     0\n",
       "cats__SaleCondition_Partial    0\n",
       "nums__LotFrontage              0\n",
       "nums__LotArea                  0\n",
       "nums__garage_age               0\n",
       "nums__TotRmsAbvGrd             0\n",
       "nums__Fireplaces               0\n",
       "cats__MSSubClass_30            0\n",
       "cats__MSSubClass_40            0\n",
       "nums__WoodDeckSF               0\n",
       "nums__OpenPorchSF              0\n",
       "nums__EnclosedPorch            0\n",
       "nums__3SsnPorch                0\n",
       "nums__ScreenPorch              0\n",
       "nums__PoolArea                 0\n",
       "nums__MiscVal                  0\n",
       "nums__MoSold                   0\n",
       "nums__age                      0\n",
       "nums__age_mod                  0\n",
       "cats__MSSubClass_180           0\n",
       "cats__MSSubClass_160           0\n",
       "cats__MSZoning_FV              0\n",
       "cats__MSZoning_RH              0\n",
       "cats__MSZoning_RL              0\n",
       "cats__MSZoning_RM              0\n",
       "cats__Street_Grvl              0\n",
       "cats__Street_Pave              0\n",
       "cats__LotShape_IR1             0\n",
       "cats__LotShape_IR2             0\n",
       "cats__LotShape_IR3             0\n",
       "cats__LotShape_Reg             0\n",
       "cats__LandContour_Bnk          0\n",
       "cats__LandContour_HLS          0\n",
       "cats__LandContour_Low          0\n",
       "cats__LandContour_Lvl          0\n",
       "cats__MSSubClass_20            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7df29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5324e8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = bestestimator.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2bb0403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cat=cat_search.best_estimator_.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bd8dc7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_best= cat_search.best_estimator_\n",
    "cat_best.fit(X,y)\n",
    "y_pred_cat=cat_search.best_estimator_.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "46520990",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best=bestestimator\n",
    "xgb_best.fit(X,y)\n",
    "y_pred_xgb = xgb_best.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546813c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    'Id': test_df['Id'],'SalePrice': y_pred_xgb})\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e2f4b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble predictions\n",
    "submission_df = pd.DataFrame({\n",
    "    'Id': test_df['Id'],'SalePrice': (y_pred_xgb+ y_pred_cat)/2})\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e9cb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "606a6ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 17:14:39,401] A new study created in memory with name: no-name-7a036c82-f128-4d9d-b7ea-2b84fedc0132\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.242e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:39,733] Trial 0 finished with value: 0.9004132714170028 and parameters: {'alpha': 7.32711707118323, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.388e+10, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:40,529] Trial 1 finished with value: 0.8928686535433804 and parameters: {'alpha': 0.16772284042492483, 'max_iter': 5000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.987e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:40,694] Trial 2 finished with value: 0.898786344838459 and parameters: {'alpha': 3.7181036518823105, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.043e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:41,650] Trial 3 finished with value: 0.8954683328653429 and parameters: {'alpha': 1.484878472552504, 'max_iter': 5000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.659e+10, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:41,810] Trial 4 finished with value: 0.8960700974040279 and parameters: {'alpha': 1.7200078251124848, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "[I 2025-06-22 17:14:42,554] Trial 5 finished with value: 0.8934868753366871 and parameters: {'alpha': 0.4472404824452999, 'max_iter': 10000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.252e+10, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:44,627] Trial 6 finished with value: 0.8927753701156383 and parameters: {'alpha': 0.0012930994394778578, 'max_iter': 10000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.085e+11, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:44,812] Trial 7 finished with value: 0.8933395129009563 and parameters: {'alpha': 0.02793194868163479, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.267e+10, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:45,749] Trial 8 finished with value: 0.8926306067676043 and parameters: {'alpha': 0.041547352447560415, 'max_iter': 5000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.246e+11, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:47,697] Trial 9 finished with value: 0.8928157644755836 and parameters: {'alpha': 0.00020056187099233759, 'max_iter': 10000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e+11, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:48,102] Trial 10 finished with value: 0.8934100988720969 and parameters: {'alpha': 0.002745772437164316, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.367e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:48,274] Trial 11 finished with value: 0.9003960646138369 and parameters: {'alpha': 6.307193925632501, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.235e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:48,461] Trial 12 finished with value: 0.9003325925765451 and parameters: {'alpha': 8.868694356019589, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.369e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:48,652] Trial 13 finished with value: 0.9003576461093026 and parameters: {'alpha': 9.853248663292044, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.029e+10, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:48,816] Trial 14 finished with value: 0.8936990902193209 and parameters: {'alpha': 0.42311689034993616, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.796e+11, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:48,983] Trial 15 finished with value: 0.8933116322203339 and parameters: {'alpha': 0.10374047451111329, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.152e+11, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:49,154] Trial 16 finished with value: 0.8933951742828851 and parameters: {'alpha': 0.009102305414500121, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.848e+10, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:49,327] Trial 17 finished with value: 0.8943387623506244 and parameters: {'alpha': 0.8068041366195279, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:50,257] Trial 18 finished with value: 0.8986554496859606 and parameters: {'alpha': 3.668502199693203, 'max_iter': 5000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.393e+10, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:51,974] Trial 19 finished with value: 0.8929285825883314 and parameters: {'alpha': 0.18178943679257903, 'max_iter': 10000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.257e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:52,139] Trial 20 finished with value: 0.8983344827685815 and parameters: {'alpha': 3.310621461991054, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.341e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:52,330] Trial 21 finished with value: 0.9003573096984104 and parameters: {'alpha': 9.6370014768922, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.200e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:52,510] Trial 22 finished with value: 0.9003218223367501 and parameters: {'alpha': 8.611771334501599, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.625e+10, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:52,673] Trial 23 finished with value: 0.8956927530730485 and parameters: {'alpha': 1.4937487735338117, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.548e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:52,856] Trial 24 finished with value: 0.8998017147903103 and parameters: {'alpha': 4.9010117188639635, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.042e+10, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:53,031] Trial 25 finished with value: 0.8939870730908293 and parameters: {'alpha': 0.626509411843759, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.413e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:53,197] Trial 26 finished with value: 0.8964773460609083 and parameters: {'alpha': 1.9720114167509544, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+11, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:53,376] Trial 27 finished with value: 0.8934170949173814 and parameters: {'alpha': 0.0001492709879503008, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "[I 2025-06-22 17:14:54,174] Trial 28 finished with value: 0.9003564504866228 and parameters: {'alpha': 9.795235043436795, 'max_iter': 5000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.380e+10, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:56,110] Trial 29 finished with value: 0.8927662955705681 and parameters: {'alpha': 0.10847992096242527, 'max_iter': 10000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.404e+10, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:57,043] Trial 30 finished with value: 0.89306750256825 and parameters: {'alpha': 0.24477741675765505, 'max_iter': 5000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.427e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:57,220] Trial 31 finished with value: 0.9001749674182766 and parameters: {'alpha': 5.557478936846182, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.873e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:57,394] Trial 32 finished with value: 0.8976237048339106 and parameters: {'alpha': 2.7405727084607303, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.492e+10, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:57,557] Trial 33 finished with value: 0.8941958159742356 and parameters: {'alpha': 0.7717555255855028, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.456e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:57,732] Trial 34 finished with value: 0.900086419294815 and parameters: {'alpha': 5.37384938342582, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.565e+10, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:57,898] Trial 35 finished with value: 0.8951278930484194 and parameters: {'alpha': 1.170665911345045, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.708e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:58,064] Trial 36 finished with value: 0.8977859026225117 and parameters: {'alpha': 2.860392446008082, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.355e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:14:58,254] Trial 37 finished with value: 0.9003576335623968 and parameters: {'alpha': 9.747667111713362, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:15:00,066] Trial 38 finished with value: 0.8954122183939284 and parameters: {'alpha': 1.451521032392965, 'max_iter': 10000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.696e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:15:00,966] Trial 39 finished with value: 0.8998693251156398 and parameters: {'alpha': 5.045652468666273, 'max_iter': 5000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:15:01,135] Trial 40 finished with value: 0.8934167029077172 and parameters: {'alpha': 0.00041507399737990925, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.256e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:15:01,316] Trial 41 finished with value: 0.9003405326430466 and parameters: {'alpha': 9.011241674649716, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.515e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:15:01,487] Trial 42 finished with value: 0.8970820738419897 and parameters: {'alpha': 2.3630789335653555, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.382e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:15:01,678] Trial 43 finished with value: 0.9003572059466913 and parameters: {'alpha': 9.95492007462555, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.503e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:15:01,861] Trial 44 finished with value: 0.8999414430315107 and parameters: {'alpha': 5.117008388665693, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.118e+11, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:15:02,031] Trial 45 finished with value: 0.8933663016254259 and parameters: {'alpha': 0.018571674673832233, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "[I 2025-06-22 17:15:03,008] Trial 46 finished with value: 0.8932457809499328 and parameters: {'alpha': 0.3296304660629442, 'max_iter': 10000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.530e+10, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:15:03,169] Trial 47 finished with value: 0.8948186745733492 and parameters: {'alpha': 1.0124071945726103, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:15:03,336] Trial 48 finished with value: 0.8934061236915951 and parameters: {'alpha': 0.004660736696203123, 'max_iter': 1000}. Best is trial 0 with value: 0.9004132714170028.\n",
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.851e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-22 17:15:04,223] Trial 49 finished with value: 0.9003539436161749 and parameters: {'alpha': 6.1443220645115355, 'max_iter': 5000}. Best is trial 0 with value: 0.9004132714170028.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 7.32711707118323, 'max_iter': 1000}\n",
      "Best R2 score: 0.9004132714170028\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def lasso_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-4, 10, log=True)\n",
    "    max_iter = trial.suggest_categorical('max_iter', [1000, 5000, 10000])\n",
    "    model = Lasso(alpha=alpha, max_iter=max_iter, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return r2_score(y_test, preds)\n",
    "\n",
    "lasso_study = optuna.create_study(direction='maximize')\n",
    "lasso_study.optimize(lasso_objective, n_trials=50)\n",
    "\n",
    "print(\"Best parameters:\", lasso_study.best_params)\n",
    "print(\"Best R2 score:\", lasso_study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2a956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.242e+09, tolerance: 6.967e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[110]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m best_lasso = Lasso(**lasso_study.best_params, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m      3\u001b[39m best_lasso.fit(X_train,y_train)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m y_pred_lasso = best_lasso.predict(X_test_new)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:298\u001b[39m, in \u001b[36mLinearModel.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    285\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m    Predict using the linear model.\u001b[39;00m\n\u001b[32m    287\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    296\u001b[39m \u001b[33;03m        Returns predicted values.\u001b[39;00m\n\u001b[32m    297\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decision_function(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1150\u001b[39m, in \u001b[36mElasticNet._decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m.coef_.T, dense_output=\u001b[38;5;28;01mTrue\u001b[39;00m) + \u001b[38;5;28mself\u001b[39m.intercept_\n\u001b[32m   1149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()._decision_function(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:277\u001b[39m, in \u001b[36mLinearModel._decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    275\u001b[39m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     X = validate_data(\u001b[38;5;28mself\u001b[39m, X, accept_sparse=[\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcoo\u001b[39m\u001b[33m\"\u001b[39m], reset=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    278\u001b[39m     coef_ = \u001b[38;5;28mself\u001b[39m.coef_\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m coef_.ndim == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2954\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2952\u001b[39m         out = X, y\n\u001b[32m   2953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m     out = check_array(X, input_name=\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m, **check_params)\n\u001b[32m   2955\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1105\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m     )\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     _assert_all_finite(\n\u001b[32m   1106\u001b[39m         array,\n\u001b[32m   1107\u001b[39m         input_name=input_name,\n\u001b[32m   1108\u001b[39m         estimator_name=estimator_name,\n\u001b[32m   1109\u001b[39m         allow_nan=ensure_all_finite == \u001b[33m\"\u001b[39m\u001b[33mallow-nan\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1110\u001b[39m     )\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1114\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m _assert_all_finite_element_wise(\n\u001b[32m    121\u001b[39m     X,\n\u001b[32m    122\u001b[39m     xp=xp,\n\u001b[32m    123\u001b[39m     allow_nan=allow_nan,\n\u001b[32m    124\u001b[39m     msg_dtype=msg_dtype,\n\u001b[32m    125\u001b[39m     estimator_name=estimator_name,\n\u001b[32m    126\u001b[39m     input_name=input_name,\n\u001b[32m    127\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MiniConda\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nLasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Retrain Lasso with best parameters from Optuna\n",
    "best_lasso = Lasso(**lasso_study.best_params, random_state=42)\n",
    "best_lasso.fit(X,y)\n",
    "y_pred_lasso = best_lasso.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2798040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble predictions\n",
    "submission_df = pd.DataFrame({\n",
    "    'Id': test_df['Id'],'SalePrice': (y_pred_xgb+ y_pred_cat+y_pred_lasso)/3})\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee962293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df07262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
